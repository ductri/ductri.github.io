<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Đức Trí Nguyễn</title>
    <link>https://ductri.github.io/post/index.xml</link>
    <description>Recent content in Posts on Đức Trí Nguyễn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2016 younetco company</copyright>
    <lastBuildDate>Sat, 18 Mar 2017 00:37:24 +0700</lastBuildDate>
    <atom:link href="https://ductri.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Xác suất trong học máy</title>
      <link>https://ductri.github.io/post/xac-suat-trong-hoc-may/</link>
      <pubDate>Sat, 18 Mar 2017 00:37:24 +0700</pubDate>
      
      <guid>https://ductri.github.io/post/xac-suat-trong-hoc-may/</guid>
      <description>

&lt;p&gt;Trong bài này, mình sẽ tổng hợp lại các khái niệm cơ bản trong xác suất, các hướng tiếp cận xác suất. Đặc biệt, mình sẽ giải thích tên gọi một số loại xác suất hay được nhắc tới trong học máy. Mình viết hoàn toàn tiếng việt, chỗ nào chen dô tiếng anh chỉ là thuật ngữ, để ai đọc sách tiếng anh dễ nhận biết.&lt;/p&gt;

&lt;p&gt;Xác suất là một phân ngành trong toán học, mà theo giáo sư toán Arthur Benjamin (được biết đến như một nhà ảo thuật toán &amp;ldquo;Mathemagician&amp;rdquo;) đề nghị trong bài TED talk của ông: mọi người nên học xác suất và thống kê trước khi học giải tích.&lt;/p&gt;

&lt;p&gt;Trong lĩnh vực IA, nhiều giải thuật nổi tiếng sử dụng hoặc có liên quan đến lý thuyết xác suất như: Hidden Markov Model, Bayesian Network, hoặc việc chứng minh mức độ của Random Forrest, &amp;hellip; Việc hiểu căn bản lý thuyết xác suất, đặc biệt là hiểu các định nghĩa hay dùng là rất cần thiết cho việc hiểu bản chất vấn đề và cách giải quyết trong các giải thuật học máy.&lt;/p&gt;

&lt;p&gt;Cá nhân mình thấy mình có &amp;ldquo;hơi&amp;rdquo; nắm được lý thuyết xác suất. Nhưng xưa giờ toàn học trên tiếng Việt, nên khi đọc sách tiếng Anh lòi ra kha khá khái niệm mới mẻ, hay ho, giờ viết ra để tự hệ thống lại. Mình dự định sẽ viết 2 bài. Nội dung trong bài đầu này giới thiệu sơ lược lại về xác suất, cung cấp cái nhìn tổng quát trên góc nhìn toán học, chưa liên quan gì học máy ở đây cả&amp;hellip; Bài sau sẽ mô tả chi tiết các thuật ngữ hay gặp: prior probability, likelihood probability, posterial probability, conditional probability.&lt;/p&gt;

&lt;h1 id=&#34;1-các-cách-hiểu-về-xác-suất&#34;&gt;1. Các cách hiểu về xác suất&lt;/h1&gt;

&lt;p&gt;Hiện nay có hơn một cách hiểu về xác suất ([1], [2], [3], [4]). Vì chúng ta chỉ quan tâm trong ngữ cảnh học máy, nên mình tham khảo theo Bishop[3], ông cho rằng có 2 hướng tiếp cận: Frenqtist Interpretation Probability (gọi tắt trong bài là FIP) và Bayesian Probability (gọi tắt trong bài là BP). Hướng FIP hiểu xác suất như tỉ lệ số lần thử nghiệm thành công, chia số lần thử nghiệm; hoặc số mẫu phù hợp chia cho kích thước không gian mẫu. Cách tiếp cận này mang hơi hướng của thống kê. Cách tiếp cận này dễ hiểu.&lt;/p&gt;

&lt;p&gt;Cách tiếp cận thứ hai BP tổng quát hơn, cũng có phần tự nhiên hơn. Ví dụ với các phát biểu như: khả năng trái đất sẽ bị hủy diệt trong 100 năm tới, khả năng chiến tranh thế giới thứ 3 nổ ra, &amp;hellip; Các sự kiện trên rất hiếm khi xảy ra, hoặc chưa bao giờ xảy ra, nên không thể tiến hành các thử nghiệm để tính xác suất theo cách hiểu FIP. Hướng tiếp cận BP có tính tổng quát hơn. Xác suất được hiểu như một độ đo về mức độ tin tưởng. Từ đó, chúng ta có thể gán xác suất cho cả các sự kiện chưa bao giờ xảy ra.&lt;/p&gt;

&lt;h1 id=&#34;2-xác-suất-trên-biến-rời-rạc-và-liên-tục&#34;&gt;2. Xác suất trên biến rời rạc và liên tục&lt;/h1&gt;

&lt;p&gt;Khi nói đến xác suất, người ta ngầm định là đang nói đến xác suất trên một/nhiều biến (biến cố). Khi nói đến xác suất chung chung, ta thường bị nhầm lẫn giữa hai khái niệm. Khái niệm thường mặc định được hiểu là xác suất khi một biến cố X nhận giá trị x0, được ký hiện là p(X = x0), đôi khi được viết tắt là p(x0). Ví dụ như nói trong hộp có 3 bi đỏ, 5 bi xanh, 4 bi vàng, 2 bi xám, thì xác suất để chọn được bi đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;. Nói như vậy nghĩa là xác suất để biến cố chọn bi (X) trúng bi màu đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;, p(X = bi đỏ) = &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;.&lt;/p&gt;

&lt;p&gt;Khái niệm thứ hai tổng quát hơn: phân phối xác suất (probability distribution) trên biến cố X, được ký hiện là p(X). Ta đi tìm xác suất cho mọi giá trị mà biến cố X có thể có, rồi tính xác suất cho từng giá trị đó, thì sẽ có được một phân phối xác suất. Trong ví dụ trên, tính thêm các xác suất p(X = bi xanh), p(X = bi vàng), p(X = bi xám),  thì ta sẽ có được phân phối xác suất cho biến X (biến cố X).&lt;/p&gt;

&lt;p&gt;Có 2 loại biến: biến rời rạc (dicrete variable) và biến liên tục (continuous variable). Ở ví dụ trên, X là một biến rời rạc. Để mô tả phân phối xác suất cho biến rời rạc, ta lập một bảng tương tự như Bảng 1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bảng 1.&lt;/strong&gt; Bảng phân phối xác suất trên biến X&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/bang-phan-phoi-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bảng 1 được gọi là Bảng phân phối xác suất trên biến X. Đây là cách để mô tả phân phối xác suất đối với biến rời rạc. Tuy nhiên, để Bảng 1 được gọi như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị pi &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các pi = 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hình 1.&lt;/strong&gt; Biểu đồ phân bố xác suất&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/bieu-do-phan-bo-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/ham-mat-do-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Ngoài ra, Bảng 1 còn có thể được mô hình hóa như Hình 1. Nếu số lượng các cột đủ nhiều, tiến dần đến vô cùng, ta sẽ dần có được cách biểu diễn xác suất cho biến liên tục. Chỉ cần chỉnh sửa Biểu đồ 2.1 một chút, xóa hết các cột đi, làm mịn các đường nối lại, ta được Biểu đồ 2.1b là Hàm mật độ xác suất trên biến X. Đây là cách biểu diễn phân phối xác suất cho biến liên tục. Cũng tương tự như biến rời rạc, để hàm trên được gọi tên nghe kêu như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị f(x0) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các giá trị f(x) được tính bằng Tích phân&amp;hellip; = 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tới đây ta có được hai cách mô tả về xác suất: Bảng phân phối xác suất (cho biến rời rạc) và Hàm mật độ xác suất (cho biến liên tục). Trong tiếng Anh, Hàm mật độ xác suất được dịch là Probability Density Function, tên này được viết tắt nghe rất hay: PDF. Còn Bảng phân phối xác suất thì mình ít thấy người ta dịch thuần qua tiếng Anh là Table of Probability Distribution (mặc dù search google vẫn ra). Người ta hay gọi hoặch toẹt luôn là Probability Density Function of X, rồi nói X là biến rời rạc. Một cách gọi khác ngắn hơn cũng thường dùng là Probability Mass Function. &amp;ldquo;Mass&amp;rdquo; ở đây chỉ &amp;ldquo;đống&amp;rdquo; giá trị rời rạc. Ở đây, dễ có sự lẫn lộn giữa Probability Distribution với Probability Density/Mass Function. Qua tìm hiểu thì mình thấy Probability Density/Mass Function là một cái riêng, cụ thể của Probability Distribution.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>