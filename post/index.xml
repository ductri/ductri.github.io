<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Đức Trí Nguyễn</title>
    <link>https://ductri.github.io/post/index.xml</link>
    <description>Recent content in Posts on Đức Trí Nguyễn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2016 younetco company</copyright>
    <lastBuildDate>Tue, 02 May 2017 16:12:58 +0700</lastBuildDate>
    <atom:link href="https://ductri.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Linear Regression - Yêu em lần nữa</title>
      <link>https://ductri.github.io/post/linear-regression-yeu-em-lan-nua/</link>
      <pubDate>Tue, 02 May 2017 16:12:58 +0700</pubDate>
      
      <guid>https://ductri.github.io/post/linear-regression-yeu-em-lan-nua/</guid>
      <description>

&lt;p&gt;Yêu một người đến được lúc cưới là đã yêu người đó nhiều hơn một lần. Đọc ở đâu đó thấy vậy. Mình với em nó quen nhau cũng được một thời gian rồi. Đến nay chưa xác định cưới xin gì nhưng mình cảm nhận được là mình đang yêu em nó lần thứ hai. Nay mình viết bài này để ôn lại về chuyện tình mình với em nó.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Mô tả lại số đo 3 vòng của em nó (&lt;em&gt;Linear Regression&lt;/em&gt;): Cho trước tập data $ X=\{\mathsf{x_1}, \mathsf{x_2}, &amp;hellip;, \mathsf{x_n} \} $ có nhãn tương ứng $T=\{t_1, t_2, &amp;hellip;, t_n\}$. Tìm (dự đoán) giá trị $y$ tại điểm $\mathsf{x}$ bất kỳ với giả sử y có thể biểu diễn tuyển tính thông qua $\mathsf{x}$.&lt;/p&gt;

&lt;h3 id=&#34;một-số-quy-ước&#34;&gt;&lt;em&gt;Một số quy ước&lt;/em&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;$X$: tập hợp&lt;/li&gt;
&lt;li&gt;$x$: biến x có giá trị scala&lt;/li&gt;
&lt;li&gt;$\mathsf{x}$: biến x là vectec&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cách-truyền-thống-để-tán-em-nó&#34;&gt;Cách truyền thống để tán em nó&lt;/h3&gt;

&lt;p&gt;Chúng ta giả sử: $$y = f(\mathsf{x}) = \mathsf{w}\mathsf{x} = w_0 + w_1x_1 + w_2x_2 + &amp;hellip; + w_nx_n$$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ban đầu khởi tạo $\mathsf{w}=[w_0, w_1, w_2, &amp;hellip;, w_n]$ bất kỳ.&lt;/li&gt;
&lt;li&gt;Tính hàm chi phí $L = \frac{1}{2}\sum_{i=1}^{n} t_i (t_i - y_i)^2$.&lt;/li&gt;
&lt;li&gt;Dùng &lt;em&gt;gradient descent&lt;/em&gt; để tìm hướng mà $\mathsf{w}$ giảm, cập nhật $\mathsf{w}$ mới.&lt;/li&gt;
&lt;li&gt;Lặp lại bước 2 cho đến khi $L$ nhỏ hơn mức mà mình cảm thấy thoải mãn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cuối cùng ta có được $\mathsf{w}$, nghĩa là có được công thức thần thánh $y = \mathsf{w}\mathsf{x}$. Từ nay cần là thay $\mathsf{x}$ vào, ta có ngay $y$. Vậy là em nó thuộc về mình :v&lt;/p&gt;

&lt;h3 id=&#34;cách-hiện-đại-để-tán-em-nó&#34;&gt;Cách hiện đại để tán em nó&lt;/h3&gt;

&lt;p&gt;Cách tán truyền thống của thế hệ 0x trên khá ổn, tuy nhiên giới trẻ thích cái mới. Bọn nó thích thả thính sành điệu hơn. Vậy là bọn nhỏ dạy mình cách cách tán em nó bằng xác suất.
Trước khi áp dụng cách tán này, chúng ta cần nhìn 3 vòng của em nó với một ánh mắt khác: Cũng cùng giả thiết như trên, nhưng yêu cầu không chỉ là tìm một giá trị $y$ tại điểm $\mathsf{x}$ bất kỳ, mà tìm phân bố xác suất của $y$ tại điểm $\mathsf{x}$ bất kỳ. Tức là thay vì đi tìm $y=f(\mathsf{x})$, ta đi tìm $p(y|\mathsf{x})$.&lt;/p&gt;

&lt;p&gt;Nói là tìm phân bố xác suất, nhưng ta cần một giả sử để thu hẹp phạm vi tìm kiếm: xác suất cần tìm có phân phối tự nhiên $p(y|\mathsf{x}, \mathsf{w}) = N(y|f(\mathsf{x}), \sigma^2)$ với $f(\mathsf{x})$ chính là &lt;strong&gt;mean&lt;/strong&gt; của phân bố xác suất. Điều này có nghĩa với mỗi $\mathsf{x}$, ta xác định phân bố $N(y|f(x), \sigma^2)$, với $f(\mathsf{x})$ được xác định như cũ, $f(\mathsf{x}) = \mathsf{w}\mathsf{x} = w_0 + w_1x_1 + w_2x_2 + &amp;hellip; + w_nx_n$.&lt;/p&gt;

&lt;p&gt;Với giả thiết ta có là $X$, $T$, để xác định $\mathsf{w}$ và $\sigma^2$, ta dùng &lt;em&gt;Maximum likelihood&lt;/em&gt; trên xác suất $p(T|X, \mathsf{w}, \sigma^2)$&lt;/p&gt;

&lt;p&gt;Ta có:
$$p = N(y|f(\mathsf{x}), \sigma^2)$$
Áp dụng công thức trên cho tất cả các điểm trong tập dữ liệu huấn luyện:
$$p_1 = N(y|f(\mathsf{x_1}), \sigma^2)$$
$$p_2 = N(y|f(\mathsf{x_2}), \sigma^2)$$
$$&amp;hellip;$$
$$p_n = N(y|f(\mathsf{x_n}), \sigma^2)$$&lt;/p&gt;

&lt;p&gt;Vì các xác suất trên độc lập nhau, suy ra:&lt;/p&gt;

&lt;p&gt;$$p(T|X, \mathsf{w}, \sigma^2) = \prod p_i = \prod N(t_i|f(\mathsf{x}_i), \sigma^2)$$
$$\Leftrightarrow \log_p(T|X, \mathsf{w}, \sigma^2) = $$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Xác suất trong học máy (Phần 2)</title>
      <link>https://ductri.github.io/post/xac-suat-trong-hoc-may-phan2/</link>
      <pubDate>Sun, 19 Mar 2017 10:19:05 +0700</pubDate>
      
      <guid>https://ductri.github.io/post/xac-suat-trong-hoc-may-phan2/</guid>
      <description>

&lt;p&gt;Xác suất là một phân ngành trong toán học, mà theo giáo sư toán Arthur Benjamin (được biết đến như một nhà ảo thuật toán &amp;ldquo;Mathemagician&amp;rdquo;) đề nghị trong bài TED talk của ông: mọi người nên học xác suất và thống kê trước khi học giải tích.&lt;/p&gt;

&lt;p&gt;Trong lĩnh vực IA, nhiều giải thuật có liên quan đến lý thuyết xác suất như: Hidden Markov Model, Bayesian Network, chứng minh ưu điểm của Random Forrest,&amp;hellip; Việc hiểu căn bản lý thuyết xác suất, đặc biệt là hiểu các định nghĩa hay dùng là rất cần thiết cho việc hiểu bản chất vấn đề và cách giải quyết trong các giải thuật học máy.&lt;/p&gt;

&lt;p&gt;Tiếp theo &lt;a href=&#34;https://ductri.github.io/post/xac-suat-trong-hoc-may/&#34;&gt;&lt;em&gt;phần 1&lt;/em&gt;&lt;/a&gt;, trong bài viết này mình sẽ nói chi tiết về các thuật ngữ xác suất hay gặp trong các giải thuật học máy. Xác suất trong học máy thường xuất hiện các khái niệm: xác suất tiên nghiệm (&lt;em&gt;prior probability&lt;/em&gt;), xác suất hậu nghiệm (&lt;em&gt;posterial probability&lt;/em&gt;), hàm &lt;em&gt;likelihood&lt;/em&gt;, xác suất có điều kiện (&lt;em&gt;conditional probability&lt;/em&gt;). Vấn đề cốt lõi các của bài toán học máy là tìm tham số w, sao cho mô hình (model) f khi nhận vào một giá trị x, cùng với tham số w, cho ra kết quả giống với thực tế nhất. Để hỗ trợ cho việc tìm w, ta thường có tập dữ liệu D cho trước. Tất nhiên w, x có thể là giá trị scala, cũng có thể có nhiều chiều. Nhưng để đơn giản, cứ tạm thời xem chúng là giá trị scala.&lt;/p&gt;

&lt;h1 id=&#34;1-xác-suất-tiên-nghiệm&#34;&gt;1. Xác suất tiên nghiệm&lt;/h1&gt;

&lt;p&gt;Cách đơn giản, ngây thơ (vô số tội) là cho ngẫu nhiên w. Khi đó ta đụng đến khái niệm đầu tiên: p(w) được gọi là xác suất tiên nghiệm (&lt;em&gt;prior probability&lt;/em&gt;). p(w) là phân phối xác suất trên w, lưu ý là phân phối xác suất, chứ ko phải là xác suất. Phân phối này hoặc là Mass, hoặc là Density. Điều này có nghĩa tổng xác suất lấy trên toàn miền giá trị w bằng 1. p(w) phản ánh sự chủ quan đối với biến w, bởi vì đơn thuần dựa trên trực giác, ta gán cho w một phân phối xác suất.&lt;/p&gt;

&lt;h1 id=&#34;2-xác-suất-hậu-nghiệm&#34;&gt;2. Xác suất hậu nghiệm&lt;/h1&gt;

&lt;p&gt;Tiếp theo, ta sử dụng đến giả thiết đã có D. Đến lược p(w|D) xuất hiện. Đây là một xác suất có điều kiện (&lt;em&gt;conditional probability&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Xác suất có điều kiện là xác suất với kết quả của một biến cố đã được biết trước. Lưu ý điều này không có nghĩa là biến cố đó phải xảy ra trước. Một bài toán đơn giản để mô tả về xác suất có điều kiện như sau: Có 2 hộp trắng và 1 hộp đen. Trong mỗi hộp trắng có 3 bi đỏ, 7 bi xanh. Trong mỗi hộp đen có 4 bi đỏ, 6 bi xanh. Chọn một hộp bất kỳ, sau đó lấy ngẫu nhiên 1 viên bi. Tìm xác suất để hộp được chọn là hộp trắng khi đã biết viên bi chọn ra có màu xanh. Đây là một xác suất có điều kiện, với điều kiện là một biến cố (chọn viên bi) xảy ra sau biến cố (chọn hộp) cần tìm xác suất.&lt;/p&gt;

&lt;p&gt;Quay trở lại p(w|D). Nhớ rằng p(w|D) là một hàm trên biến w. p(w|D) phản ánh sự ước lượng cho w khi đã biết D. Xác suất này được gọi là xác suất hậu nghiệm (&lt;em&gt;posterial probability&lt;/em&gt;), bởi vì chúng ta đang ước lượng cho w sau khi đã biết thông tin về D. Xác suất này tương ứng với việc tìm xác suất để chọn được bi xanh sau khi đã chọn hộp màu trắng. Tương tự như p(w), đây cũng là một Mass hoặc Density (tùy loại biến), cho nên tổng xác suất có điều kiện (D) trên toàn miền giá trị w cũng bằng 1.&lt;/p&gt;

&lt;h1 id=&#34;3-hàm-likelihood&#34;&gt;3. Hàm likelihood&lt;/h1&gt;

&lt;p&gt;Xác suất cuối cùng, và mình thấy hay nhất là hàm &lt;em&gt;likelihood&lt;/em&gt;: p(D|w). Nếu đã cảm thấy p(w|D) khá tự nhiên thì đến xác suất này tạo cảm giác khó hiểu lạ thường. Nhớ rằng D là cái mình đã có, w là cái mình cần tìm. Nghĩa là p(D|w) vẫn là hàm trên w như p(w|D), nhưng khác biệt là tổng xác suất trên toàn miền giá trị w không bằng 1, vì về mặt xác suất thì p(D|w) là phân bố xác suất có điều kiện trên D. Về bản chất thì rõ ràng nó là xác suất, nhưng người ta chỉ nói làm hàm likelihood chứ không gọi là xác suất likelihood. Theo mình thì người ta gọi như vậy để phân biệt với p(w) và p(w|D). Hai xác suất này là 2 phân bố xác suất thuộc &lt;em&gt;mass/density probability distribution&lt;/em&gt; trên biến w, tức là xét trên toàn miền giá trị w thì tổng giá trị xác suất luôn bằng 1. Còn p(D|w) tuy cũng là &lt;em&gt;mass/density probability distribution&lt;/em&gt; nhưng lại đối với biến D, nên tổng xác suất trên miền giá trị w không nhất thiết bằng 1.&lt;/p&gt;

&lt;p&gt;Ý nghĩa xác suất p(D|w) là thể hiện độ phù hợp của D đối với những giá trị w khác nhau. Mục đính chính của học máy thể hiện ở đây: Ta mong muốn tìm w để đạt được giá trị tối đa của p(D|w), nghĩa là tìm w sao cho phù hợp nhất với tập D đã có.&lt;/p&gt;

&lt;p&gt;Cuộc sống nhiều chuyện vượt quá tầm tay ta, D là một trong những cái đó. Trong khi đó, cách ta bước tiếp, cách ta đáp ứng với cái D đó (w), ta có thể kiểm soát được. Vậy nên thôi đừng hỏi vì sao D xảy ra, đừng mong chờ D sẽ thay đổi (dữ liệu training có sẳn rồi, cố định bà nó rồi), hãy điều chỉnh w sao cho phù hợp với D nhất, tìm w để tối ưu hóa p(D|w), đó mới là điều cần boăn khoăn, cần suy nghĩ. Nhưng cụ thể làm sao thì là chuyện riêng của mỗi bác giải thuật học máy, ở đây mình không bàn.&lt;/p&gt;

&lt;h1 id=&#34;4-quan-hệ-giữa-ba-xác-suất-trên&#34;&gt;4. Quan hệ giữa ba xác suất trên&lt;/h1&gt;

&lt;p&gt;Chốt chỗ này cái. Ta có ba xác suất: xác suất tiền nghiệm, xác suất hậu nghiệm và hàm likelihood. Quan hệ của ba xác suất suất thể hiện qua công thức xác suất Bayesian:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;p(w|D) = p(D|w) x p(w) / p(D)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Vì D là cái đã có và cố định, ta xem p(D) như hằng số. Khi đó:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;p(w|D) ~ p(D|w) x p(w)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;posterial probability ~ likelihood probability x prior probability&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Công thức trên là nền tảng cơ bản cho các giải thuật học máy, cho ta một cái nhìn về bản chất về vấn đề cần giải quyết trong học máy.&lt;/p&gt;

&lt;h1 id=&#34;tham-khảo&#34;&gt;Tham khảo&lt;/h1&gt;

&lt;p&gt;Bishop, Christopher M. &amp;ldquo;Pattern recognition.&amp;rdquo; Machine Learning 128 (2006).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Xác suất trong học máy (Phần 1)</title>
      <link>https://ductri.github.io/post/xac-suat-trong-hoc-may/</link>
      <pubDate>Sat, 18 Mar 2017 00:37:24 +0700</pubDate>
      
      <guid>https://ductri.github.io/post/xac-suat-trong-hoc-may/</guid>
      <description>

&lt;p&gt;Trong bài này, mình sẽ tổng hợp lại các khái niệm cơ bản trong xác suất, các hướng tiếp cận xác suất. Đặc biệt, mình sẽ giải thích tên gọi một số loại xác suất hay được nhắc tới trong học máy. Mình viết hoàn toàn tiếng việt, chỗ nào chen dô tiếng anh chỉ là thuật ngữ, để ai đọc sách tiếng anh dễ nhận biết.&lt;/p&gt;

&lt;p&gt;Cá nhân mình thấy mình có &amp;ldquo;hơi&amp;rdquo; nắm được lý thuyết xác suất. Nhưng xưa giờ toàn học trên tiếng Việt, nên khi đọc sách tiếng Anh lòi ra kha khá khái niệm mới mẻ, hay ho, giờ viết ra để tự hệ thống lại. Vì dài quá nên mình chia làm 2 bài. Nội dung trong bài đầu này giới thiệu sơ lược lại về xác suất, cung cấp cái nhìn tổng quát trên góc nhìn toán học, chưa liên quan gì học máy ở đây cả&amp;hellip; Bài sau sẽ mô tả chi tiết các thuật ngữ hay gặp: prior probability, likelihood probability, posterial probability, conditional probability.&lt;/p&gt;

&lt;h1 id=&#34;1-các-cách-hiểu-về-xác-suất&#34;&gt;1. Các cách hiểu về xác suất&lt;/h1&gt;

&lt;p&gt;Hiện nay có hơn một cách hiểu về xác suất ([1], [2], [3], [4]). Vì chúng ta chỉ quan tâm trong ngữ cảnh học máy, nên mình tham khảo theo Bishop[3], ông cho rằng có 2 hướng tiếp cận: &lt;strong&gt;Frenqtist Interpretation Probability&lt;/strong&gt; (gọi tắt trong bài là FIP) và &lt;strong&gt;Bayesian Probability&lt;/strong&gt; (gọi tắt trong bài là BP). Hướng FIP hiểu xác suất như tỉ lệ số lần thử nghiệm thành công, chia số lần thử nghiệm; hoặc số mẫu phù hợp chia cho kích thước không gian mẫu. Cách tiếp cận này mang hơi hướng của thống kê. Cách tiếp cận này dễ hiểu.&lt;/p&gt;

&lt;p&gt;Cách tiếp cận thứ hai BP tổng quát hơn, cũng có phần tự nhiên hơn. Ví dụ với các phát biểu như: khả năng trái đất sẽ bị hủy diệt trong 100 năm tới, khả năng chiến tranh thế giới thứ 3 nổ ra, &amp;hellip; Các sự kiện trên rất hiếm khi xảy ra, hoặc chưa bao giờ xảy ra, nên không thể tiến hành các thử nghiệm để tính xác suất theo cách hiểu FIP. Hướng tiếp cận BP có tính tổng quát hơn. Xác suất được hiểu như một độ đo về mức độ tin tưởng. Từ đó, chúng ta có thể gán xác suất cho cả các sự kiện chưa bao giờ xảy ra.&lt;/p&gt;

&lt;h1 id=&#34;2-xác-suất-trên-biến-ngẫu-nhiên-rời-rạc-và-liên-tục&#34;&gt;2. Xác suất trên biến ngẫu nhiên rời rạc và liên tục&lt;/h1&gt;

&lt;p&gt;Khi nói đến xác suất, người ta ngầm định là đang nói đến xác suất trên một/nhiều biến (biến cố). Ta thường bị nhầm lẫn giữa hai khái niệm. Khái niệm thường mặc định được hiểu là xác suất khi một biến cố X nhận giá trị x&lt;sub&gt;0&lt;/sub&gt;, được ký hiện là p(X = x&lt;sub&gt;0&lt;/sub&gt;), đôi khi được viết tắt là p(x&lt;sub&gt;0&lt;/sub&gt;). Ví dụ như nói trong hộp có 3 bi đỏ, 5 bi xanh, 4 bi vàng, 2 bi xám, thì xác suất để chọn được bi đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;. Nói như vậy nghĩa là xác suất để biến cố chọn bi (X) trúng bi màu đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;, p(X = bi đỏ) = &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;.&lt;/p&gt;

&lt;p&gt;Khái niệm thứ hai tổng quát hơn: phân phối xác suất (&lt;strong&gt;probability distribution&lt;/strong&gt;) trên biến cố X, được ký hiện là p(X). Ta đi tìm xác suất cho mọi giá trị mà biến cố X có thể có, rồi tính xác suất cho từng giá trị đó, thì sẽ có được một phân phối xác suất. Trong ví dụ trên, tính thêm các xác suất p(X = bi xanh), p(X = bi vàng), p(X = bi xám),  thì ta sẽ có được phân phối xác suất cho biến X (biến cố X).&lt;/p&gt;

&lt;p&gt;Có 2 loại biến ngẫu nhiên: biến ngẫu nhiên rời rạc (&lt;strong&gt;dicrete variable&lt;/strong&gt;) và biến ngẫu nhiên liên tục (&lt;strong&gt;continuous variable&lt;/strong&gt;). Ở ví dụ trên, X là một biến ngẫu nhiên rời rạc. Để mô tả phân phối xác suất cho biến ngẫu nhiên rời rạc, ta lập một bảng tương tự như Bảng 1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bảng 1.&lt;/strong&gt; Bảng phân phối xác suất trên biến X&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/bang-phan-phoi-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bảng 1 được gọi là Bảng phân phối xác suất trên biến X. Đây là cách để mô tả phân phối xác suất đối với biến ngẫu nhiên rời rạc. Tuy nhiên, để Bảng 1 được gọi như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị p(X = x&lt;sub&gt;i&lt;/sub&gt;) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các p(X = x&lt;sub&gt;i&lt;/sub&gt;) = 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/bieu-do-phan-bo-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 1.&lt;/strong&gt; Biểu đồ phân bố xác suất&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/ham-mat-do-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 2.&lt;/strong&gt; Hàm mật độ xác suất&lt;/p&gt;

&lt;p&gt;Ngoài ra, Bảng 1 còn có thể được mô hình hóa như Hình 1. Nếu số lượng các cột đủ nhiều, tiến dần đến vô cùng, ta sẽ dần có được cách biểu diễn xác suất cho biến ngẫu nhiên liên tục. Chỉ cần chỉnh sửa Hình 1 một chút, xóa hết các cột đi, làm mịn các đường nối lại, ta được Hình 2 là hàm mật độ xác suất trên biến X. Đây là cách biểu diễn phân phối xác suất cho biến ngẫu nhiên liên tục. Cũng tương tự như biến ngẫu nhiên rời rạc, để hàm trên được gọi tên nghe kêu như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị f(x&lt;sub&gt;i&lt;/sub&gt;) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các giá trị f(x) bằng 1, trong trường hợp này X liên tục nên tích phân trên toàn miền X bằng 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tới đây ta có được hai cách mô tả về xác suất: Bảng phân phối xác suất (cho biến ngẫu nhiên rời rạc) và Hàm mật độ xác suất (cho biến ngẫu nhiên liên tục). Trong tiếng Anh, hàm mật độ xác suất được dịch là &lt;strong&gt;Probability Density Function&lt;/strong&gt;, tên này được viết tắt nghe rất hay: &lt;strong&gt;PDF&lt;/strong&gt;. Còn Bảng phân phối xác suất thì mình ít thấy người ta dịch thuần qua tiếng Anh là Table of Probability Distribution (mặc dù search google vẫn ra). Người ta hay gọi hoặch toẹt luôn là &lt;strong&gt;Probability Density Function of X&lt;/strong&gt;, rồi nói X là biến ngẫu nhiên rời rạc. Một cách gọi khác ngắn hơn cũng thường dùng là &lt;strong&gt;Probability Mass Function&lt;/strong&gt;. &amp;ldquo;Mass&amp;rdquo; ý chỉ &amp;ldquo;đống&amp;rdquo; giá trị rời rạc.&lt;/p&gt;

&lt;p&gt;Ở đây, dễ có sự lẫn lộn giữa &lt;strong&gt;Probability Distribution&lt;/strong&gt; với &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt;. Nhớ rằng &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt; là một cái riêng, cái cụ thể của &lt;strong&gt;Probability Distribution&lt;/strong&gt;. Chỉ khi nào &lt;strong&gt;Probability Distribution&lt;/strong&gt; thỏa 2 điều kiện  mới được gọi là &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị P(X=x&lt;sub&gt;0&lt;/sub&gt;) lớn hơn 0&lt;/li&gt;
&lt;li&gt;Tổng P(X) trên toàn miền giá trị X bằng 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Xong, hết phần 1. Phần 2 sẽ nói xác suất trong ngữ cảnh học máy.&lt;/p&gt;

&lt;h2 id=&#34;tham-khảo&#34;&gt;Tham khảo&lt;/h2&gt;

&lt;p&gt;[1] Phan Huy Khải, Các bài toán tổ hợp. Nhà xuất bản giáo dục&lt;/p&gt;

&lt;p&gt;[2] Wikipedia, &lt;a href=&#34;https://en.wikipedia.org/wiki/Frequentist_probability&#34;&gt;https://en.wikipedia.org/wiki/Frequentist_probability&lt;/a&gt;, phần Alternative views&lt;/p&gt;

&lt;p&gt;[3] Bishop, Christopher M. &amp;ldquo;Pattern recognition.&amp;rdquo; Machine Learning 128 (2006): 1-58.&lt;/p&gt;

&lt;p&gt;[4] Slide Xác suất thống kê - Trường Đại học Bách Khoa TP.HCM&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>