<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Đức Trí Nguyễn</title>
    <link>https://ductri.github.io/index.xml</link>
    <description>Recent content on Đức Trí Nguyễn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2016 younetco company</copyright>
    <lastBuildDate>Sat, 18 Mar 2017 00:37:24 +0700</lastBuildDate>
    <atom:link href="https://ductri.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Xác suất trong học máy (Phần 1)</title>
      <link>https://ductri.github.io/post/xac-suat-trong-hoc-may/</link>
      <pubDate>Sat, 18 Mar 2017 00:37:24 +0700</pubDate>
      
      <guid>https://ductri.github.io/post/xac-suat-trong-hoc-may/</guid>
      <description>

&lt;p&gt;Trong bài này, mình sẽ tổng hợp lại các khái niệm cơ bản trong xác suất, các hướng tiếp cận xác suất. Đặc biệt, mình sẽ giải thích tên gọi một số loại xác suất hay được nhắc tới trong học máy. Mình viết hoàn toàn tiếng việt, chỗ nào chen dô tiếng anh chỉ là thuật ngữ, để ai đọc sách tiếng anh dễ nhận biết.&lt;/p&gt;

&lt;p&gt;Cá nhân mình thấy mình có &amp;ldquo;hơi&amp;rdquo; nắm được lý thuyết xác suất. Nhưng xưa giờ toàn học trên tiếng Việt, nên khi đọc sách tiếng Anh lòi ra kha khá khái niệm mới mẻ, hay ho, giờ viết ra để tự hệ thống lại. Vì dài quá nên mình chia làm 2 bài. Nội dung trong bài đầu này giới thiệu sơ lược lại về xác suất, cung cấp cái nhìn tổng quát trên góc nhìn toán học, chưa liên quan gì học máy ở đây cả&amp;hellip; Bài sau sẽ mô tả chi tiết các thuật ngữ hay gặp: prior probability, likelihood probability, posterial probability, conditional probability.&lt;/p&gt;

&lt;h1 id=&#34;1-các-cách-hiểu-về-xác-suất&#34;&gt;1. Các cách hiểu về xác suất&lt;/h1&gt;

&lt;p&gt;Hiện nay có hơn một cách hiểu về xác suất ([1], [2], [3], [4]). Vì chúng ta chỉ quan tâm trong ngữ cảnh học máy, nên mình tham khảo theo Bishop[3], ông cho rằng có 2 hướng tiếp cận: &lt;strong&gt;Frenqtist Interpretation Probability&lt;/strong&gt; (gọi tắt trong bài là FIP) và &lt;strong&gt;Bayesian Probability&lt;/strong&gt; (gọi tắt trong bài là BP). Hướng FIP hiểu xác suất như tỉ lệ số lần thử nghiệm thành công, chia số lần thử nghiệm; hoặc số mẫu phù hợp chia cho kích thước không gian mẫu. Cách tiếp cận này mang hơi hướng của thống kê. Cách tiếp cận này dễ hiểu.&lt;/p&gt;

&lt;p&gt;Cách tiếp cận thứ hai BP tổng quát hơn, cũng có phần tự nhiên hơn. Ví dụ với các phát biểu như: khả năng trái đất sẽ bị hủy diệt trong 100 năm tới, khả năng chiến tranh thế giới thứ 3 nổ ra, &amp;hellip; Các sự kiện trên rất hiếm khi xảy ra, hoặc chưa bao giờ xảy ra, nên không thể tiến hành các thử nghiệm để tính xác suất theo cách hiểu FIP. Hướng tiếp cận BP có tính tổng quát hơn. Xác suất được hiểu như một độ đo về mức độ tin tưởng. Từ đó, chúng ta có thể gán xác suất cho cả các sự kiện chưa bao giờ xảy ra.&lt;/p&gt;

&lt;h1 id=&#34;2-xác-suất-trên-biến-ngẫu-nhiên-rời-rạc-và-liên-tục&#34;&gt;2. Xác suất trên biến ngẫu nhiên rời rạc và liên tục&lt;/h1&gt;

&lt;p&gt;Khi nói đến xác suất, người ta ngầm định là đang nói đến xác suất trên một/nhiều biến (biến cố). Ta thường bị nhầm lẫn giữa hai khái niệm. Khái niệm thường mặc định được hiểu là xác suất khi một biến cố X nhận giá trị x&lt;sub&gt;0&lt;/sub&gt;, được ký hiện là p(X = x&lt;sub&gt;0&lt;/sub&gt;), đôi khi được viết tắt là p(x&lt;sub&gt;0&lt;/sub&gt;). Ví dụ như nói trong hộp có 3 bi đỏ, 5 bi xanh, 4 bi vàng, 2 bi xám, thì xác suất để chọn được bi đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;. Nói như vậy nghĩa là xác suất để biến cố chọn bi (X) trúng bi màu đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;, p(X = bi đỏ) = &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;.&lt;/p&gt;

&lt;p&gt;Khái niệm thứ hai tổng quát hơn: phân phối xác suất (&lt;strong&gt;probability distribution&lt;/strong&gt;) trên biến cố X, được ký hiện là p(X). Ta đi tìm xác suất cho mọi giá trị mà biến cố X có thể có, rồi tính xác suất cho từng giá trị đó, thì sẽ có được một phân phối xác suất. Trong ví dụ trên, tính thêm các xác suất p(X = bi xanh), p(X = bi vàng), p(X = bi xám),  thì ta sẽ có được phân phối xác suất cho biến X (biến cố X).&lt;/p&gt;

&lt;p&gt;Có 2 loại biến ngẫu nhiên: biến ngẫu nhiên rời rạc (&lt;strong&gt;dicrete variable&lt;/strong&gt;) và biến ngẫu nhiên liên tục (&lt;strong&gt;continuous variable&lt;/strong&gt;). Ở ví dụ trên, X là một biến ngẫu nhiên rời rạc. Để mô tả phân phối xác suất cho biến ngẫu nhiên rời rạc, ta lập một bảng tương tự như Bảng 1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bảng 1.&lt;/strong&gt; Bảng phân phối xác suất trên biến X&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/bang-phan-phoi-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bảng 1 được gọi là Bảng phân phối xác suất trên biến X. Đây là cách để mô tả phân phối xác suất đối với biến ngẫu nhiên rời rạc. Tuy nhiên, để Bảng 1 được gọi như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị p(X = x&lt;sub&gt;i&lt;/sub&gt;) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các p(X = x&lt;sub&gt;i&lt;/sub&gt;) = 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/bieu-do-phan-bo-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 1.&lt;/strong&gt; Biểu đồ phân bố xác suất&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ductri.github.io/img/ham-mat-do-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 2.&lt;/strong&gt; Hàm mật độ xác suất&lt;/p&gt;

&lt;p&gt;Ngoài ra, Bảng 1 còn có thể được mô hình hóa như Hình 1. Nếu số lượng các cột đủ nhiều, tiến dần đến vô cùng, ta sẽ dần có được cách biểu diễn xác suất cho biến ngẫu nhiên liên tục. Chỉ cần chỉnh sửa Hình 1 một chút, xóa hết các cột đi, làm mịn các đường nối lại, ta được Hình 2 là hàm mật độ xác suất trên biến X. Đây là cách biểu diễn phân phối xác suất cho biến ngẫu nhiên liên tục. Cũng tương tự như biến ngẫu nhiên rời rạc, để hàm trên được gọi tên nghe kêu như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị f(x&lt;sub&gt;i&lt;/sub&gt;) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các giá trị f(x) bằng 1, trong trường hợp này X liên tục nên tích phân trên toàn miền X bằng 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tới đây ta có được hai cách mô tả về xác suất: Bảng phân phối xác suất (cho biến ngẫu nhiên rời rạc) và Hàm mật độ xác suất (cho biến ngẫu nhiên liên tục). Trong tiếng Anh, hàm mật độ xác suất được dịch là &lt;strong&gt;Probability Density Function&lt;/strong&gt;, tên này được viết tắt nghe rất hay: &lt;strong&gt;PDF&lt;/strong&gt;. Còn Bảng phân phối xác suất thì mình ít thấy người ta dịch thuần qua tiếng Anh là Table of Probability Distribution (mặc dù search google vẫn ra). Người ta hay gọi hoặch toẹt luôn là &lt;strong&gt;Probability Density Function of X&lt;/strong&gt;, rồi nói X là biến ngẫu nhiên rời rạc. Một cách gọi khác ngắn hơn cũng thường dùng là &lt;strong&gt;Probability Mass Function&lt;/strong&gt;. &amp;ldquo;Mass&amp;rdquo; ý chỉ &amp;ldquo;đống&amp;rdquo; giá trị rời rạc.&lt;/p&gt;

&lt;p&gt;Ở đây, dễ có sự lẫn lộn giữa &lt;strong&gt;Probability Distribution&lt;/strong&gt; với &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt;. Nhớ rằng &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt; là một cái riêng, cái cụ thể của &lt;strong&gt;Probability Distribution&lt;/strong&gt;. Chỉ khi nào &lt;strong&gt;Probability Distribution&lt;/strong&gt; thỏa 2 điều kiện  mới được gọi là &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị P(X=x&lt;sub&gt;0&lt;/sub&gt;) lớn hơn 0&lt;/li&gt;
&lt;li&gt;Tổng P(X) trên toàn miền giá trị X bằng 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Xong, hết phần 1. Phần 2 sẽ nói xác suất trong ngữ cảnh học máy.&lt;/p&gt;

&lt;h2 id=&#34;tham-khảo&#34;&gt;Tham khảo&lt;/h2&gt;

&lt;p&gt;[1] Phan Huy Khải, Các bài toán tổ hợp. Nhà xuất bản giáo dục
[2] Wikipedia, &lt;a href=&#34;https://en.wikipedia.org/wiki/Frequentist_probability&#34;&gt;https://en.wikipedia.org/wiki/Frequentist_probability&lt;/a&gt;, phần Alternative views
[3] Bishop, Christopher M. &amp;ldquo;Pattern recognition.&amp;rdquo; Machine Learning 128 (2006): 1-58.
[4] Slide Xác suất thống kê - Trường Đại học Bách Khoa TP.HCM&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>