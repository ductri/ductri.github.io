<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Classic</title>
    <link>/index.xml</link>
    <description>Recent content on Classic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Jul 2017 16:12:58 +0700</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Bài toán Linear Regression từ góc nhìn xác suất</title>
      <link>/post/2017/07/23/b%C3%A0i-to%C3%A1n-linear-regression-t%E1%BB%AB-g%C3%B3c-nh%C3%ACn-x%C3%A1c-su%E1%BA%A5t/</link>
      <pubDate>Sun, 23 Jul 2017 16:12:58 +0700</pubDate>
      
      <guid>/post/2017/07/23/b%C3%A0i-to%C3%A1n-linear-regression-t%E1%BB%AB-g%C3%B3c-nh%C3%ACn-x%C3%A1c-su%E1%BA%A5t/</guid>
      <description>

&lt;hr /&gt;

&lt;p&gt;Bài toán Linear Regression được phát biểu như sau:
Cho tập data $\{d \in D| d_j = y_j, x_{j1}, x_{j2}, &amp;hellip;, x_{jn} \} $, với giả định rằng: với mỗi điểm dữ liệu $d_j$, biến phụ thuộc $y_j$ phụ thuộc tuyến tính vào n biến độc lập $x_{j1}, x_{j2}, &amp;hellip;, x_{jn}$. Mối quan hệ trên được biểu diễn bằng:
$$y_j = \epsilon + w_1x_{j1} + w_2x_{j2} + w_3x_{j3} + &amp;hellip; +  + w_nx_{jn} = \epsilon + WX$$
Biến $\epsilon$ có thể được coi như biến ngẫu nhiên thể hiện độ nhiễu của những giá trị quan sát được (các giá trị $x_i, y_i$).&lt;/p&gt;

&lt;p&gt;Từ đây, ta xem giá trị $y$ như một biến ngẫu nhiên có hàm mật độ xác suất $p(y|X, W, \epsilon)$. Bây giờ giả sử hàm mật độ xác suất $p$ là một phân bố Gaussian với mean là WX, và thông số lỗi $\epsilon$ được thể hiện thông qua độ lệch chuẩn $\beta$.
$$ p(y|X, W, \epsilon) = \mathcal{N}(WX, \beta)$$&lt;/p&gt;

&lt;p&gt;Mô tả lại số đo 3 vòng của em nó (&lt;em&gt;Linear Regression&lt;/em&gt;): Cho trước tập data $ X=\{\mathsf{x_1}, \mathsf{x_2}, &amp;hellip;, \mathsf{x_n} \} $ có nhãn tương ứng $T=\{t_1, t_2, &amp;hellip;, t_n\}$. Tìm (dự đoán) giá trị $y$ tại điểm $\mathsf{x}$ bất kỳ với giả sử y có thể biểu diễn tuyển tính thông qua $\mathsf{x}$.&lt;/p&gt;

&lt;h3 id=&#34;một-số-quy-ước&#34;&gt;&lt;em&gt;Một số quy ước&lt;/em&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;$X$: tập hợp&lt;/li&gt;
&lt;li&gt;$x$: biến x có giá trị scala&lt;/li&gt;
&lt;li&gt;$\mathsf{x}$: biến x là vectec&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cách-truyền-thống-để-tán-em-nó&#34;&gt;Cách truyền thống để tán em nó&lt;/h3&gt;

&lt;p&gt;Chúng ta giả sử: $$y = f(\mathsf{x}) = \mathsf{w}\mathsf{x} = w_0 + w_1x_1 + w_2x_2 + &amp;hellip; + w_nx_n$$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ban đầu khởi tạo $\mathsf{w}=[w_0, w_1, w_2, &amp;hellip;, w_n]$ bất kỳ.&lt;/li&gt;
&lt;li&gt;Tính hàm chi phí $L = \frac{1}{2}\sum_{i=1}^{n} t_i (t_i - y_i)^2$.&lt;/li&gt;
&lt;li&gt;Dùng &lt;em&gt;gradient descent&lt;/em&gt; để tìm hướng mà $\mathsf{w}$ giảm, cập nhật $\mathsf{w}$ mới.&lt;/li&gt;
&lt;li&gt;Lặp lại bước 2 cho đến khi $L$ nhỏ hơn mức mà mình cảm thấy thoải mãn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cuối cùng ta có được $\mathsf{w}$, nghĩa là có được công thức thần thánh $y = \mathsf{w}\mathsf{x}$. Từ nay cần là thay $\mathsf{x}$ vào, ta có ngay $y$. Vậy là em nó thuộc về mình :v&lt;/p&gt;

&lt;h3 id=&#34;cách-hiện-đại-để-tán-em-nó&#34;&gt;Cách hiện đại để tán em nó&lt;/h3&gt;

&lt;p&gt;Cách tán truyền thống của thế hệ 0x trên khá ổn, tuy nhiên giới trẻ thích cái mới. Bọn nó thích thả thính sành điệu hơn. Vậy là bọn nhỏ dạy mình cách cách tán em nó bằng xác suất.
Trước khi áp dụng cách tán này, chúng ta cần nhìn 3 vòng của em nó với một ánh mắt khác: Cũng cùng giả thiết như trên, nhưng yêu cầu không chỉ là tìm một giá trị $y$ tại điểm $\mathsf{x}$ bất kỳ, mà tìm phân bố xác suất của $y$ tại điểm $\mathsf{x}$ bất kỳ. Tức là thay vì đi tìm $y=f(\mathsf{x})$, ta đi tìm $p(y|\mathsf{x})$.&lt;/p&gt;

&lt;p&gt;Nói là tìm phân bố xác suất, nhưng ta cần một giả sử để thu hẹp phạm vi tìm kiếm: xác suất cần tìm có phân phối tự nhiên $p(y|\mathsf{x}, \mathsf{w}) = N(y|f(\mathsf{x}), \sigma^2)$ với $f(\mathsf{x})$ chính là &lt;strong&gt;mean&lt;/strong&gt; của phân bố xác suất. Điều này có nghĩa với mỗi $\mathsf{x}$, ta xác định phân bố $N(y|f(x), \sigma^2)$, với $f(\mathsf{x})$ được xác định như cũ, $f(\mathsf{x}) = \mathsf{w}\mathsf{x} = w_0 + w_1x_1 + w_2x_2 + &amp;hellip; + w_nx_n$.&lt;/p&gt;

&lt;p&gt;Với giả thiết ta có là $X$, $T$, để xác định $\mathsf{w}$ và $\sigma^2$, ta dùng &lt;em&gt;Maximum likelihood&lt;/em&gt; trên xác suất $p(T|X, \mathsf{w}, \sigma^2)$&lt;/p&gt;

&lt;p&gt;Ta có:
$$p = N(y|f(\mathsf{x}), \sigma^2)$$
Áp dụng công thức trên cho tất cả các điểm trong tập dữ liệu huấn luyện:
$$p_1 = N(y|f(\mathsf{x_1}), \sigma^2)$$
$$p_2 = N(y|f(\mathsf{x_2}), \sigma^2)$$
$$&amp;hellip;$$
$$p_n = N(y|f(\mathsf{x_n}), \sigma^2)$$&lt;/p&gt;

&lt;p&gt;Vì các xác suất trên độc lập nhau, suy ra:&lt;/p&gt;

&lt;p&gt;$$p(T|X, \mathsf{w}, \sigma^2) = \prod p_i = \prod N(t_i|f(\mathsf{x}_i), \sigma^2)$$
$$\Leftrightarrow \log_p(T|X, \mathsf{w}, \sigma^2) = $$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gradient - Cái giống khó hiểu :3</title>
      <link>/post/2017/05/28/gradient---c%C3%A1i-gi%E1%BB%91ng-kh%C3%B3-hi%E1%BB%83u-3/</link>
      <pubDate>Sun, 28 May 2017 22:19:54 +0700</pubDate>
      
      <guid>/post/2017/05/28/gradient---c%C3%A1i-gi%E1%BB%91ng-kh%C3%B3-hi%E1%BB%83u-3/</guid>
      <description>

&lt;p&gt;&lt;em&gt;Gradient Descent&lt;/em&gt; là cụm từ được nghe rất nhiều khi học về MLP, Neuron Network, hay CNN. Quen em nó nhau lâu rồi, nhìn mặt nhau miết, tưởng mình đã hiểu nhau, mà tới nay mới vẽ lẽ vừa không hiểu và vừa hiểu sai em nó quá trời&amp;hellip; Nay nhờ hoàn cảnh đưa đẩy mà mình hiểu thêm được em nó chút xíu.&lt;/p&gt;

&lt;h3 id=&#34;gradient-em-nó-là-ai&#34;&gt;Gradient - em nó là ai ?&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Gradient&lt;/em&gt; của một hàm $f(x_1, x_2, &amp;hellip;, x_n)$, được ký hiệu $\nabla f$ là một vector $n$ chiều, mà mỗi thành phần trong vector đó là một đạo hàm riêng phần (&lt;em&gt;partial derivative&lt;/em&gt;) theo từng biến của hàm đó:
$$
\bbox[20px,border:1px solid black] {
\nabla f=(\frac{df}{dx_1}, \frac{df}{dx_1}, &amp;hellip;, \frac{df}{dx_n})
}
$$&lt;/p&gt;

&lt;p&gt;Sau đây là 2 điều mình mới hiểu ra:&lt;/p&gt;

&lt;h3 id=&#34;1-vector-gradient-tại-một-điểm-cho-mình-biết-từ-điểm-đó-hướng-nào-làm-tăng-giá-trị-f-nhiều-nhất-có-thể-tại-sao-lại-là-tăng&#34;&gt;&lt;strong&gt;1. Vector gradient tại một điểm cho mình biết từ điểm đó, hướng nào làm tăng giá trị $f$ nhiều nhất có thể. Tại sao lại là tăng ?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Chấp nhận điều này lâu rồi, tự nhiên hôm qua mới ngớ ra: Tại sao lại là hướng tăng (Hình 1) mà không phải là hướng giảm ?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/gradient-what-the-fuck-is-this/myth1.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 1.&lt;/strong&gt; Hướng của vector &lt;em&gt;gradient&lt;/em&gt; luôn chỉ về phía cao hơn&lt;/p&gt;

&lt;p&gt;Wow wow, là vì do ông nào định nghĩa nó như vậy :v. Mỗi thành phần của vector &lt;em&gt;gradient&lt;/em&gt; là một đạo hàm riêng phần, giờ thử xét $\frac{df}{dx}$.
Định nghĩa đạo hàm theo [1]:
$$\frac{df}{dx} = \frac{f(x+\epsilon)-f(x)}{\epsilon}$$
với $\epsilon&amp;gt;0$ và đủ nhỏ. Mấu chốt đều nằm ở ông $\epsilon$, vì $ \epsilon&amp;gt;0$, nên chiều của $\frac{df}{dx}$ chỉ còn phụ thuộc vào tử số.&lt;/p&gt;

&lt;p&gt;Từ đó ta xét 2 trường hợp $\vec{AB}$ và $\vec{CD}$ sẽ hiểu:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Vector AB: $$\frac{df}{dx}=\frac{f(A) - f(B)}{x_A - x_B}$$
Vì $f(A)&amp;lt;f(B)$ (trong trường hợp này), cho nên tử âm, $\vec{AB}$ chỉ về hướng âm, cũng là hướng của $f$ tăng.&lt;/li&gt;
&lt;li&gt;Vector CD: $$\frac{df}{dx}=\frac{f(D) - f( C)}{x_D - x_C}$$
Vì $f( C)&amp;lt;f(D)$ (trong trường hợp này), cho nên tử dương, $\vec{CD}$ chỉ về hướng dương, cũng là hướng của $f$ tăng.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vì vậy mà $\frac{df}{dx}$ luôn chỉ về hướng $f$ tăng.&lt;/p&gt;

&lt;h3 id=&#34;2-vector-gradient-trực-giao-perpendicular-với-contour-line-của-hàm&#34;&gt;&lt;strong&gt;2. Vector &lt;em&gt;gradient&lt;/em&gt; trực giao (&lt;em&gt;perpendicular&lt;/em&gt;) với &lt;em&gt;contour line&lt;/em&gt; của hàm&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Điều này nghe bực mình + rối rắm kinh khủng khi cứ nhớ lớp 12, được học đạo hàm của hàm $y = f(x)$ tại $x_0$ chính là pháp tuyến của $f(x)$ tại $x_0$. Rà lại, đọc về đạo hàm (&lt;em&gt;derivative&lt;/em&gt;) thấy đâu đâu cũng vẽ hình tiếp tuyến [1], cái khỉ gì giờ lại là trực giao ? Với vừa nãy ở trên mới nói là hướng làm tăng $f$, sao giờ lại có chuyện trực giao ở đây ?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/gradient-what-the-fuck-is-this/myth2a.png&#34; alt=&#34;Example image&#34; /&gt;
&lt;img src=&#34;/img/gradient-what-the-fuck-is-this/myth2b.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;strong&gt;Hình 2.&lt;/strong&gt; Vector trong hình 2.a hay 2.b mới đúng là vector &lt;em&gt;gradient&lt;/em&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Mấu chốt nằm ở khái niệm &lt;em&gt;contour line&lt;/em&gt;. Nó có vài tên khác nhau: contour line, level set, level curve. Định nghĩa ở đây cả [2]. Đại khái một contour line là tập hợp những điểm làm cho hàm có cùng một giá trị $y_0$ nào đó. Hàm có miền vô hạn thì cũng có nghĩa là có vô số contour line.&lt;/p&gt;

&lt;p&gt;Vậy là Hình 2.a và 2.b đang biểu diễn hai đường khác nhau: đường màu đen trong hình 2.a là đồ thị biểu diễn sự phụ thuộc $y$ theo $x$ qua hàm $y=f(x)$, đường màu xanh trong hình 2.b là một đường &lt;em&gt;contour line&lt;/em&gt; biểu diễn của hàm $g(x)=0$. Mình bị nhầm lẫn bởi vì lâu nay học các hàm $y=f(x)$, đa số đều là hàm đơn biến, biểu diễn đồ thị của nó bằng tọa độ 2 chiều. Nhưng với các hàm đa biến (từ 2 biến trở lên), người ta khó biểu diễn đồ thị của hàm trên tọa độ 2 chiều nữa, nên người ta nghĩ ra cái &lt;em&gt;contour line&lt;/em&gt; dễ biểu diễn hơn.&lt;/p&gt;

&lt;p&gt;Khi học về Linear Regression, $y=WX + b$, người ta thường lấy ví dụ $W$ và $X$ có 2 chiều, cụ thể $y=w_1x_1 + w_2x_2 + w_0$, điều này khiến mình liên tưởng đến hàm $y=ax + b$ hồi xưa có học, chỉ là chuyển vế qua thì $x$, $y$ tương ứng $w_1$, $w_2$. Điều này sai hoàn toàn, SAI ÁC LIỆT LUÔN. Chính từ đây dẫn tới những nhầm lẫn khi đọc đến vector &lt;em&gt;gradient&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Nói chính xác thì $y=ax+b$ chỉ là một phần tử trong tập &lt;em&gt;contour line&lt;/em&gt; của $y=w_1x_1 + w_2x_2 + w_0$. Và nhiệm vụ của Linear Regression là đi tìm một &lt;em&gt;contour line&lt;/em&gt; trong tập các &lt;em&gt;contour line&lt;/em&gt; ở trên.&lt;/p&gt;

&lt;p&gt;Về chuyện ngày lớp 12 được dạy rằng đạo hàm của hàm $y=f(x)$ là một vector có phương tiếp tuyến với đồ thị $f(x)$. Điều này được giải thích như sau: Hàm $y=f(x)$ là hàm một biến. Nếu vẽ theo kiểu &lt;em&gt;contour line&lt;/em&gt;, mỗi &lt;em&gt;contour line&lt;/em&gt; sẽ là 1 điểm (hoặc một vài điểm). Vì vậy mà đương nhiên nó thoải điều kiện vector &lt;em&gt;gradient&lt;/em&gt; trực giao với đường &lt;em&gt;contour line&lt;/em&gt;. Không có mâu thuẫn gì ở đây cả.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.s: Viết ra mới thấy, tuy đã hiểu, đã nắm được cái bản chất, mà muốn thể hiện nó ra vẫn khó thiệt. Bài này quá lủng cũng.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;tham-khảo&#34;&gt;&lt;strong&gt;Tham khảo&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;[1] &lt;a href=&#34;https://en.wikipedia.org/wiki/Derivative&#34;&gt;https://en.wikipedia.org/wiki/Derivative&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Level_set&#34;&gt;https://en.wikipedia.org/wiki/Level_set&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] Anzai, Yuichiro. Pattern recognition and machine learning. Elsevier, 2012.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Xác suất trong học máy (Phần 2)</title>
      <link>/post/2017/03/19/x%C3%A1c-su%E1%BA%A5t-trong-h%E1%BB%8Dc-m%C3%A1y-ph%E1%BA%A7n-2/</link>
      <pubDate>Sun, 19 Mar 2017 10:19:05 +0700</pubDate>
      
      <guid>/post/2017/03/19/x%C3%A1c-su%E1%BA%A5t-trong-h%E1%BB%8Dc-m%C3%A1y-ph%E1%BA%A7n-2/</guid>
      <description>

&lt;p&gt;Xác suất là một phân ngành trong toán học, mà theo giáo sư toán Arthur Benjamin (được biết đến như một nhà ảo thuật toán &amp;ldquo;Mathemagician&amp;rdquo;) đề nghị trong bài TED talk của ông: mọi người nên học xác suất và thống kê trước khi học giải tích.&lt;/p&gt;

&lt;p&gt;Trong lĩnh vực IA, nhiều giải thuật có liên quan đến lý thuyết xác suất như: Hidden Markov Model, Bayesian Network, chứng minh ưu điểm của Random Forrest,&amp;hellip; Việc hiểu căn bản lý thuyết xác suất, đặc biệt là hiểu các định nghĩa hay dùng là rất cần thiết cho việc hiểu bản chất vấn đề và cách giải quyết trong các giải thuật học máy.&lt;/p&gt;

&lt;p&gt;Tiếp theo &lt;a href=&#34;https://ductri.github.io/post/xac-suat-trong-hoc-may/&#34;&gt;&lt;em&gt;phần 1&lt;/em&gt;&lt;/a&gt;, trong bài viết này mình sẽ nói chi tiết về các thuật ngữ xác suất hay gặp trong các giải thuật học máy. Xác suất trong học máy thường xuất hiện các khái niệm: xác suất tiên nghiệm (&lt;em&gt;prior probability&lt;/em&gt;), xác suất hậu nghiệm (&lt;em&gt;posterial probability&lt;/em&gt;), hàm &lt;em&gt;likelihood&lt;/em&gt;, xác suất có điều kiện (&lt;em&gt;conditional probability&lt;/em&gt;). Vấn đề cốt lõi các của bài toán học máy là tìm tham số w, sao cho mô hình (model) f khi nhận vào một giá trị x, cùng với tham số w, cho ra kết quả giống với thực tế nhất. Để hỗ trợ cho việc tìm w, ta thường có tập dữ liệu D cho trước. Tất nhiên w, x có thể là giá trị scala, cũng có thể có nhiều chiều. Nhưng để đơn giản, cứ tạm thời xem chúng là giá trị scala.&lt;/p&gt;

&lt;h1 id=&#34;1-xác-suất-tiên-nghiệm&#34;&gt;1. Xác suất tiên nghiệm&lt;/h1&gt;

&lt;p&gt;Cách đơn giản, ngây thơ (vô số tội) là cho ngẫu nhiên w. Khi đó ta đụng đến khái niệm đầu tiên: p(w) được gọi là xác suất tiên nghiệm (&lt;em&gt;prior probability&lt;/em&gt;). p(w) là phân phối xác suất trên w, lưu ý là phân phối xác suất, chứ ko phải là xác suất. Phân phối này hoặc là Mass, hoặc là Density. Điều này có nghĩa tổng xác suất lấy trên toàn miền giá trị w bằng 1. p(w) phản ánh sự chủ quan đối với biến w, bởi vì đơn thuần dựa trên trực giác, ta gán cho w một phân phối xác suất.&lt;/p&gt;

&lt;h1 id=&#34;2-xác-suất-hậu-nghiệm&#34;&gt;2. Xác suất hậu nghiệm&lt;/h1&gt;

&lt;p&gt;Tiếp theo, ta sử dụng đến giả thiết đã có D. Đến lược p(w|D) xuất hiện. Đây là một xác suất có điều kiện (&lt;em&gt;conditional probability&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Xác suất có điều kiện là xác suất với kết quả của một biến cố đã được biết trước. Lưu ý điều này không có nghĩa là biến cố đó phải xảy ra trước. Một bài toán đơn giản để mô tả về xác suất có điều kiện như sau: Có 2 hộp trắng và 1 hộp đen. Trong mỗi hộp trắng có 3 bi đỏ, 7 bi xanh. Trong mỗi hộp đen có 4 bi đỏ, 6 bi xanh. Chọn một hộp bất kỳ, sau đó lấy ngẫu nhiên 1 viên bi. Tìm xác suất để hộp được chọn là hộp trắng khi đã biết viên bi chọn ra có màu xanh. Đây là một xác suất có điều kiện, với điều kiện là một biến cố (chọn viên bi) xảy ra sau biến cố (chọn hộp) cần tìm xác suất.&lt;/p&gt;

&lt;p&gt;Quay trở lại p(w|D). Nhớ rằng p(w|D) là một hàm trên biến w. p(w|D) phản ánh sự ước lượng cho w khi đã biết D. Xác suất này được gọi là xác suất hậu nghiệm (&lt;em&gt;posterial probability&lt;/em&gt;), bởi vì chúng ta đang ước lượng cho w sau khi đã biết thông tin về D. Xác suất này tương ứng với việc tìm xác suất để chọn được bi xanh sau khi đã chọn hộp màu trắng. Tương tự như p(w), đây cũng là một Mass hoặc Density (tùy loại biến), cho nên tổng xác suất có điều kiện (D) trên toàn miền giá trị w cũng bằng 1.&lt;/p&gt;

&lt;h1 id=&#34;3-hàm-likelihood&#34;&gt;3. Hàm likelihood&lt;/h1&gt;

&lt;p&gt;Xác suất cuối cùng, và mình thấy hay nhất là hàm &lt;em&gt;likelihood&lt;/em&gt;: p(D|w). Nếu đã cảm thấy p(w|D) khá tự nhiên thì đến xác suất này tạo cảm giác khó hiểu lạ thường. Nhớ rằng D là cái mình đã có, w là cái mình cần tìm. Nghĩa là p(D|w) vẫn là hàm trên w như p(w|D), nhưng khác biệt là tổng xác suất trên toàn miền giá trị w không bằng 1, vì về mặt xác suất thì p(D|w) là phân bố xác suất có điều kiện trên D. Về bản chất thì rõ ràng nó là xác suất, nhưng người ta chỉ nói làm hàm likelihood chứ không gọi là xác suất likelihood. Theo mình thì người ta gọi như vậy để phân biệt với p(w) và p(w|D). Hai xác suất này là 2 phân bố xác suất thuộc &lt;em&gt;mass/density probability distribution&lt;/em&gt; trên biến w, tức là xét trên toàn miền giá trị w thì tổng giá trị xác suất luôn bằng 1. Còn p(D|w) tuy cũng là &lt;em&gt;mass/density probability distribution&lt;/em&gt; nhưng lại đối với biến D, nên tổng xác suất trên miền giá trị w không nhất thiết bằng 1.&lt;/p&gt;

&lt;p&gt;Ý nghĩa xác suất p(D|w) là thể hiện độ phù hợp của D đối với những giá trị w khác nhau. Mục đính chính của học máy thể hiện ở đây: Ta mong muốn tìm w để đạt được giá trị tối đa của p(D|w), nghĩa là tìm w sao cho phù hợp nhất với tập D đã có.&lt;/p&gt;

&lt;p&gt;Cuộc sống nhiều chuyện vượt quá tầm tay ta, D là một trong những cái đó. Trong khi đó, cách ta bước tiếp, cách ta đáp ứng với cái D đó (w), ta có thể kiểm soát được. Vậy nên thôi đừng hỏi vì sao D xảy ra, đừng mong chờ D sẽ thay đổi (dữ liệu training có sẳn rồi, cố định bà nó rồi), hãy điều chỉnh w sao cho phù hợp với D nhất, tìm w để tối ưu hóa p(D|w), đó mới là điều cần boăn khoăn, cần suy nghĩ. Nhưng cụ thể làm sao thì là chuyện riêng của mỗi bác giải thuật học máy, ở đây mình không bàn.&lt;/p&gt;

&lt;h1 id=&#34;4-quan-hệ-giữa-ba-xác-suất-trên&#34;&gt;4. Quan hệ giữa ba xác suất trên&lt;/h1&gt;

&lt;p&gt;Chốt chỗ này cái. Ta có ba xác suất: xác suất tiền nghiệm, xác suất hậu nghiệm và hàm likelihood. Quan hệ của ba xác suất suất thể hiện qua công thức xác suất Bayesian:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;p(w|D) = p(D|w) x p(w) / p(D)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Vì D là cái đã có và cố định, ta xem p(D) như hằng số. Khi đó:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;p(w|D) ~ p(D|w) x p(w)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;posterial probability ~ likelihood probability x prior probability&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Công thức trên là nền tảng cơ bản cho các giải thuật học máy, cho ta một cái nhìn về bản chất về vấn đề cần giải quyết trong học máy.&lt;/p&gt;

&lt;h1 id=&#34;tham-khảo&#34;&gt;Tham khảo&lt;/h1&gt;

&lt;p&gt;Bishop, Christopher M. &amp;ldquo;Pattern recognition.&amp;rdquo; Machine Learning 128 (2006).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Xác suất trong học máy (Phần 1)</title>
      <link>/post/2017/03/18/x%C3%A1c-su%E1%BA%A5t-trong-h%E1%BB%8Dc-m%C3%A1y-ph%E1%BA%A7n-1/</link>
      <pubDate>Sat, 18 Mar 2017 00:37:24 +0700</pubDate>
      
      <guid>/post/2017/03/18/x%C3%A1c-su%E1%BA%A5t-trong-h%E1%BB%8Dc-m%C3%A1y-ph%E1%BA%A7n-1/</guid>
      <description>

&lt;p&gt;Trong bài này, mình sẽ tổng hợp lại các khái niệm cơ bản trong xác suất, các hướng tiếp cận xác suất. Đặc biệt, mình sẽ giải thích tên gọi một số loại xác suất hay được nhắc tới trong học máy. Mình viết hoàn toàn tiếng việt, chỗ nào chen dô tiếng anh chỉ là thuật ngữ, để ai đọc sách tiếng anh dễ nhận biết.&lt;/p&gt;

&lt;p&gt;Cá nhân mình thấy mình có &amp;ldquo;hơi&amp;rdquo; nắm được lý thuyết xác suất. Nhưng xưa giờ toàn học trên tiếng Việt, nên khi đọc sách tiếng Anh lòi ra kha khá khái niệm mới mẻ, hay ho, giờ viết ra để tự hệ thống lại. Vì dài quá nên mình chia làm 2 bài. Nội dung trong bài đầu này giới thiệu sơ lược lại về xác suất, cung cấp cái nhìn tổng quát trên góc nhìn toán học, chưa liên quan gì học máy ở đây cả&amp;hellip; Bài sau sẽ mô tả chi tiết các thuật ngữ hay gặp: prior probability, likelihood probability, posterial probability, conditional probability.&lt;/p&gt;

&lt;h1 id=&#34;1-các-cách-hiểu-về-xác-suất&#34;&gt;1. Các cách hiểu về xác suất&lt;/h1&gt;

&lt;p&gt;Hiện nay có hơn một cách hiểu về xác suất ([1], [2], [3], [4]). Vì chúng ta chỉ quan tâm trong ngữ cảnh học máy, nên mình tham khảo theo Bishop[3], ông cho rằng có 2 hướng tiếp cận: &lt;strong&gt;Frenqtist Interpretation Probability&lt;/strong&gt; (gọi tắt trong bài là FIP) và &lt;strong&gt;Bayesian Probability&lt;/strong&gt; (gọi tắt trong bài là BP). Hướng FIP hiểu xác suất như tỉ lệ số lần thử nghiệm thành công, chia số lần thử nghiệm; hoặc số mẫu phù hợp chia cho kích thước không gian mẫu. Cách tiếp cận này mang hơi hướng của thống kê. Cách tiếp cận này dễ hiểu.&lt;/p&gt;

&lt;p&gt;Cách tiếp cận thứ hai BP tổng quát hơn, cũng có phần tự nhiên hơn. Ví dụ với các phát biểu như: khả năng trái đất sẽ bị hủy diệt trong 100 năm tới, khả năng chiến tranh thế giới thứ 3 nổ ra, &amp;hellip; Các sự kiện trên rất hiếm khi xảy ra, hoặc chưa bao giờ xảy ra, nên không thể tiến hành các thử nghiệm để tính xác suất theo cách hiểu FIP. Hướng tiếp cận BP có tính tổng quát hơn. Xác suất được hiểu như một độ đo về mức độ tin tưởng. Từ đó, chúng ta có thể gán xác suất cho cả các sự kiện chưa bao giờ xảy ra.&lt;/p&gt;

&lt;h1 id=&#34;2-xác-suất-trên-biến-ngẫu-nhiên-rời-rạc-và-liên-tục&#34;&gt;2. Xác suất trên biến ngẫu nhiên rời rạc và liên tục&lt;/h1&gt;

&lt;p&gt;Khi nói đến xác suất, người ta ngầm định là đang nói đến xác suất trên một/nhiều biến (biến cố). Ta thường bị nhầm lẫn giữa hai khái niệm. Khái niệm thường mặc định được hiểu là xác suất khi một biến cố X nhận giá trị x&lt;sub&gt;0&lt;/sub&gt;, được ký hiện là p(X = x&lt;sub&gt;0&lt;/sub&gt;), đôi khi được viết tắt là p(x&lt;sub&gt;0&lt;/sub&gt;). Ví dụ như nói trong hộp có 3 bi đỏ, 5 bi xanh, 4 bi vàng, 2 bi xám, thì xác suất để chọn được bi đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;. Nói như vậy nghĩa là xác suất để biến cố chọn bi (X) trúng bi màu đỏ là &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;, p(X = bi đỏ) = &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;14&lt;/sub&gt;.&lt;/p&gt;

&lt;p&gt;Khái niệm thứ hai tổng quát hơn: phân phối xác suất (&lt;strong&gt;probability distribution&lt;/strong&gt;) trên biến cố X, được ký hiện là p(X). Ta đi tìm xác suất cho mọi giá trị mà biến cố X có thể có, rồi tính xác suất cho từng giá trị đó, thì sẽ có được một phân phối xác suất. Trong ví dụ trên, tính thêm các xác suất p(X = bi xanh), p(X = bi vàng), p(X = bi xám),  thì ta sẽ có được phân phối xác suất cho biến X (biến cố X).&lt;/p&gt;

&lt;p&gt;Có 2 loại biến ngẫu nhiên: biến ngẫu nhiên rời rạc (&lt;strong&gt;dicrete variable&lt;/strong&gt;) và biến ngẫu nhiên liên tục (&lt;strong&gt;continuous variable&lt;/strong&gt;). Ở ví dụ trên, X là một biến ngẫu nhiên rời rạc. Để mô tả phân phối xác suất cho biến ngẫu nhiên rời rạc, ta lập một bảng tương tự như Bảng 1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bảng 1.&lt;/strong&gt; Bảng phân phối xác suất trên biến X&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/bang-phan-phoi-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bảng 1 được gọi là Bảng phân phối xác suất trên biến X. Đây là cách để mô tả phân phối xác suất đối với biến ngẫu nhiên rời rạc. Tuy nhiên, để Bảng 1 được gọi như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị p(X = x&lt;sub&gt;i&lt;/sub&gt;) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các p(X = x&lt;sub&gt;i&lt;/sub&gt;) = 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;/img/bieu-do-phan-bo-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 1.&lt;/strong&gt; Biểu đồ phân bố xác suất&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/ham-mat-do-xac-suat.png&#34; alt=&#34;Example image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hình 2.&lt;/strong&gt; Hàm mật độ xác suất&lt;/p&gt;

&lt;p&gt;Ngoài ra, Bảng 1 còn có thể được mô hình hóa như Hình 1. Nếu số lượng các cột đủ nhiều, tiến dần đến vô cùng, ta sẽ dần có được cách biểu diễn xác suất cho biến ngẫu nhiên liên tục. Chỉ cần chỉnh sửa Hình 1 một chút, xóa hết các cột đi, làm mịn các đường nối lại, ta được Hình 2 là hàm mật độ xác suất trên biến X. Đây là cách biểu diễn phân phối xác suất cho biến ngẫu nhiên liên tục. Cũng tương tự như biến ngẫu nhiên rời rạc, để hàm trên được gọi tên nghe kêu như thế, nó cần thoải hai điều kiện:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị f(x&lt;sub&gt;i&lt;/sub&gt;) &amp;gt; 0&lt;/li&gt;
&lt;li&gt;Tổng các giá trị f(x) bằng 1, trong trường hợp này X liên tục nên tích phân trên toàn miền X bằng 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tới đây ta có được hai cách mô tả về xác suất: Bảng phân phối xác suất (cho biến ngẫu nhiên rời rạc) và Hàm mật độ xác suất (cho biến ngẫu nhiên liên tục). Trong tiếng Anh, hàm mật độ xác suất được dịch là &lt;strong&gt;Probability Density Function&lt;/strong&gt;, tên này được viết tắt nghe rất hay: &lt;strong&gt;PDF&lt;/strong&gt;. Còn Bảng phân phối xác suất thì mình ít thấy người ta dịch thuần qua tiếng Anh là Table of Probability Distribution (mặc dù search google vẫn ra). Người ta hay gọi hoặch toẹt luôn là &lt;strong&gt;Probability Density Function of X&lt;/strong&gt;, rồi nói X là biến ngẫu nhiên rời rạc. Một cách gọi khác ngắn hơn cũng thường dùng là &lt;strong&gt;Probability Mass Function&lt;/strong&gt;. &amp;ldquo;Mass&amp;rdquo; ý chỉ &amp;ldquo;đống&amp;rdquo; giá trị rời rạc.&lt;/p&gt;

&lt;p&gt;Ở đây, dễ có sự lẫn lộn giữa &lt;strong&gt;Probability Distribution&lt;/strong&gt; với &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt;. Nhớ rằng &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt; là một cái riêng, cái cụ thể của &lt;strong&gt;Probability Distribution&lt;/strong&gt;. Chỉ khi nào &lt;strong&gt;Probability Distribution&lt;/strong&gt; thỏa 2 điều kiện  mới được gọi là &lt;strong&gt;Probability Density/Mass Function&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Giá trị P(X=x&lt;sub&gt;0&lt;/sub&gt;) lớn hơn 0&lt;/li&gt;
&lt;li&gt;Tổng P(X) trên toàn miền giá trị X bằng 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Xong, hết phần 1. Phần 2 sẽ nói xác suất trong ngữ cảnh học máy.&lt;/p&gt;

&lt;h2 id=&#34;tham-khảo&#34;&gt;Tham khảo&lt;/h2&gt;

&lt;p&gt;[1] Phan Huy Khải, Các bài toán tổ hợp. Nhà xuất bản giáo dục&lt;/p&gt;

&lt;p&gt;[2] Wikipedia, &lt;a href=&#34;https://en.wikipedia.org/wiki/Frequentist_probability&#34;&gt;https://en.wikipedia.org/wiki/Frequentist_probability&lt;/a&gt;, phần Alternative views&lt;/p&gt;

&lt;p&gt;[3] Bishop, Christopher M. &amp;ldquo;Pattern recognition.&amp;rdquo; Machine Learning 128 (2006): 1-58.&lt;/p&gt;

&lt;p&gt;[4] Slide Xác suất thống kê - Trường Đại học Bách Khoa TP.HCM&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>