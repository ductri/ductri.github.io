<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tri Nguyen</title>
    <description>description</description>
    <link>https://ductri.github.io/</link>
    <atom:link href="https://ductri.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 26 Nov 2022 12:47:04 -0800</pubDate>
    <lastBuildDate>Sat, 26 Nov 2022 12:47:04 -0800</lastBuildDate>
    <generator>Jekyll v4.3.1</generator>
    
      <item>
        <title>Reinforcement Learning is So Confusing</title>
        <description>&lt;p&gt;There are many algorithms presenting in RL in a very intuitive way, but looks a bit heuristic.
While re-reading Reinforcement Learning as an attempt to get rid of that heuristic feeling, I’ve tried to digest it under an optimization perspective. And well, I realized I couldn’t make any connection whatsoever from optimization understanding to any algorithm presenting in RL.&lt;/p&gt;

&lt;p&gt;So this is an attempt to make thing more concrete under a somewhat first principle view.&lt;/p&gt;

&lt;p&gt;The note is currently very unorganized.
&lt;a href=&quot;https://ductri.github.io/assets/latex/RL_understanding/rl_understanding.pdf&quot;&gt;Let’s go!&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 22 Nov 2022 14:41:00 -0800</pubDate>
        <link>https://ductri.github.io/note/2022/11/22/RL-is-so-confusing.html</link>
        <guid isPermaLink="true">https://ductri.github.io/note/2022/11/22/RL-is-so-confusing.html</guid>
        
        <category>RL</category>
        
        
        <category>note</category>
        
      </item>
    
  </channel>
</rss>
