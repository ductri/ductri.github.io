\documentclass[11pt,a4paper]{article}
\usepackage{tri_preamble}

% --------------------------------------------------------- 
% TITLE, AUTHORS, ...
% --------------------------------------------------------- 
\title{KL Divergence and MLE}
\author{	Tri Nguyen \\\\
        \texttt{nguyetr9@oregonstate.edu} \\\\
        }
% --------------------------------------------------------- 
% BEGIN DOCUMENT
% --------------------------------------------------------- 
\begin{document}
\maketitle

\paragraph{Claim.} 
Maximizing likelihood is equivalent to minimizing KL divergence between 2 distributions x and x.

\paragraph{Derivation.} 
Assume we have $n$ i.i.d samples  $x_1, \ldots , x_n$ drawn from unknown distribution $P$. We wish to find a parameter $\theta(P)$ of $P$ using an estimator $\widehat{\theta}(x_1, \ldots , x_n)$.

% MLE recipe tells us to solve the following problem to get the ``best'' $\theta(P)$ :
% \begin{alignat*}{2}
%     & \maximize_{\widehat{\theta}} \quad && \log P(x_1, \ldots , x_n| \widehat{\theta}) 
% \end{alignat*}

To see the connection, let's write down the KL divergence
\begin{align*}
\Dkl{X|\theta}{X|\widehat{\theta}} 
&= \mathbb{E}_{X \sim P(\cdot; \theta)} \left[ \log \dfrac{P(X; \theta)}{P(X; \widehat{\theta})} \right] \\
&= \mathbb{E}_{X \sim P(\cdot; \theta)} \left[ \log P(X; \theta) \right]
- \mathbb{E}_{X \sim P(\cdot; \theta)} [\log P(X; \widehat{\theta})]
\end{align*}
Hence,  
\[
\argmin_{\widehat{\theta}} \;  \Dkl{X|\theta}{X|\widehat{\theta}}
= \argmax_{\widehat{\theta}} \;  \mathbb{E}_{X \sim P(\cdot ; \theta)} \left[  \log P(X ; \widehat{\theta}) \right]
\] 
Obviously we cannot evaluate expectation on the RHS since we do not know $\theta$. However, we have an approximation of this term thanks to $n$ i.i.d samples  $x_1, \ldots , x_n$ which are drawn from this exact distribution $P(\cdot; \theta)$.
And this is nothing but the MLE recipe:
\begin{align*}
\argmax_{\widehat{\theta}} \; \log P(x_1, \ldots , x_n ; \widehat{\theta})
&= \argmax_{\widehat{\theta}} \;  \sum^{n}_{i=1} \log P(x_i; \widehat{\theta})  \\
&= \argmax_{\widehat{\theta}} \;  \dfrac{1}{n} \sum^{n}_{i=1} \log P(x_i; \widehat{\theta}) \\
&\approx \argmax_{\widehat{\theta}} \;  \mathbb{E}_{X \sim P(\cdot; \theta)} \log P(X; \widehat{\theta})
\end{align*} 
\end{document}

