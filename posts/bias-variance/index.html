<!DOCTYPE html>
<html lang="vi">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Bias và Variance trong học máy, cụ thể là gì ? (P1) | Machine learning - The way human is teaching machine</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <header>

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

  <script>hljs.initHighlightingOnLoad();</script>
  <nav>
    <ul>
      
      
      <li class="pull-left ">
        <a href="/">/home/machine learning - the way human is teaching machine</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/">~/home</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/categories/">~/categories</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/tags/">~/tags</a>
      </li>
      

      
      
      <li class="pull-right">
        <a href="/index.xml">~/subscribe</a>
      </li>
      

    </ul>
  </nav>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110926018-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110926018-1');
</script>

</header>

  </head>

  <body>
    <br/>

<div class="article-meta">
<h1><span class="title">Bias và Variance trong học máy, cụ thể là gì ? (P1)</span></h1>

<h2 class="date">2017/09/23</h2>
<p class="terms">
  
  
  
  
  
</p>
</div>



<main>


<blockquote>
<p>Chữ <em>bias</em> này xuất hiện khá nhiều khi nói về machine learning, một ví dụ gần đây là status trên FB của lão <a href="https://www.facebook.com/yann.lecun/posts/10154777754622143">Yann LeCun</a>. Ngày xưa gặp chữ <em>bias</em> trước, nghe dịch là &ldquo;lệch&rdquo;, hoặc &ldquo;chệch&rdquo;, đáng sợ hơn nữa là &ldquo;thiên vị&rdquo;. Lúc học ML, thầy cứ nói các giải thuật học máy phải có <em>bias</em>, không có là nó không &ldquo;học&rdquo; được. Nghe cứ như triết học, ko hiểu chút gì.</p>
</blockquote>

<p>Đoạn giới thiệu ở trên không hẳn sai, mà nó dễ gây nhầm lẫn, tại bản thân mình lúc viết đoạn intro trên cũng bị nhầm lẫn. Nhờ 1 chị xinh đẹp góp ý, mới nhận ra chữ &ldquo;<em>bias</em>&rdquo; có những ý nghĩa khác nhau trong những ngữ cảnh khác nhau, sơ bộ có 3 trường hợp chính:</p>

<ol>
<li><em>bias</em> được dùng trong Neuron Network, Regression, &hellip; thường mang ý chỉ hệ số <em>bias</em> ($b$) trong công thức $y=ax + b$. Có thể ngày trước thầy nói không có bias thì giải thuật không thể học được là ý chỉ chữ <em>bias</em> này.</li>
<li><em>bias</em> trong cái post <a href="https://www.facebook.com/yann.lecun/posts/10154777754622143">Yann LeCun</a> &ldquo;hình như&rdquo; ý chỉ tới <em>inductive bias</em>.</li>
<li><em>bias</em> nói trong bài là <em>bias of an estimator</em>, đây là khái niệm đến từ xác suất thống kê. Từ chỗ này đến hết bài, chữ <em>bias</em> được hiểu thuộc loại thứ 3 này nghe :D.</li>
</ol>

<p>Trước khi đi vào định nghĩa cho từng cái, mình dùng chung các thông tin sau như ngữ cảnh mặc định:</p>

<ul>
<li>Cho trước tập dữ liệu $D={x^{(1)}, x^{(2)}, &hellip;, x^{(n)}}$. Các $x^{(i)}$ đều có <em>indepedent identically distribution (i.i.d)</em>.</li>
<li>Tập dữ liệu $D$ chỉ là một sampling may mắn có được từ không gian data $G$. Bản chất của không gian data $G$ có thể được mô tả thông ra một tập các tham số $\theta$, ví dụ như mean, max, min, &hellip;</li>
<li>Một <em>Estimator</em> (ước lượng) $\hat{\theta}$ được hiểu là một hàm bất kỳ, với đầu vào là tập dữ liệu $D$, đầu ra cố gắng trả về các tham số $\theta$ mô tả $G$. Với định nghĩa trên, ta có thể xem mọi model <em>supervised learning</em> trong học máy đều có thể coi là <em>estimator</em>, vì đường nào lúc training ta cũng nhận vào tất cả data từ $D$</li>
</ul>

<h2 id="1-bias">1. Bias</h2>

<p>Cho ví dụ, mean thực tế của $G$ là $5.5$, nghĩa là $\theta=5.5$ nhưng chúng ta không đời nào biết được điều này bởi vì chúng ta không bao giờ có được $G$. Nhiệm vụ của chúng ta là cố gắng đoán ra giá trị này thông qua <em>estimator</em> $\hat{\theta}$, mà thằng này $\hat{\theta}$ lại dựa vào data $D$. Mong muốn là nó sẽ càng gần $5.5$ càng tốt. Người ta dựa trên cái gọi là &ldquo;gần&rdquo; đó để đánh giá xem <em>estimator</em> của thằng nào tốt hơn. Và chữ &ldquo;<em>bias</em>&rdquo; ra đời từ đó.</p>

<h3 id="1-1-định-nghĩa-toán-học">1.1 Định nghĩa toán học:</h3>

<p>$$\text{bias}(\hat{\theta})= \mathbb{E}(\hat{\theta}) - \theta \tag{1} \label{bias}$$</p>

<p>Nhìn công thức trên mới hiểu cái nghĩa &ldquo;lệch/chệch&rdquo; của từ <em>bias</em>. Nếu $\text{bias}(\hat{\theta}) \neq 0$ thì ta gọi <em>estimator</em> bị <em>biased</em> (<em>biased estimator</em>), còn $\text{bias}(\hat{\theta}) = 0$ thì ta gọi là <em>unbiased estimator</em>. Rất tự nhiên là cái <em>unbiased estimator</em> tốt hơn <em>biased estimator</em>, vì cái mình ước đoán nó đúng y chang cái thiệt luôn. Giờ thử tính vài cái xem khi nào <em>bias</em> khác $0$, khi nào bằng $0$.</p>

<h4 id="ví-dụ-1">Ví dụ 1:</h4>

<p>Cho $G$ được mô tả bởi hàm phân phối xác suất Bernoulli, hàm này rất đơn giản, chỉ cần 1 tham số mean, gọi nó là $\theta$ luôn cho giống ở trên. Trong trường hợp này, $\theta$ là một số thực R, nằm trong khoảng $(0;1)$. Tập data sample $D={x^{(1)}, x^{(2)}, &hellip;, x^{(n)}}$ được chọn ra từ $G$.</p>

<p>Rồi, giờ chúng ta đi mò mẫm tìm $\theta$ dựa trên những gì đã biết (là $D$). Con tim ta mách bảo: lấy trung bình mẫu của $D$ đi, có vẻ nó sẽ khá gần với mean thiệt của $G$ luôn đó. Nghe theo tiếng gọi con tim, ta không ngần ngại chọn estimator $\hat\theta$ như sau:
$$\hat\theta = \frac{1}{n} \sum_{i=1}^{n} x^{(i)}$$
Nhưng lý trí không tin mù quáng như vậy được. Bây giờ <a href="https://youtu.be/BkBqYlLjIeA?t=86">chọn con tim hay là nghe lý trí</a>, lý trí đòi đánh giá <em>estimator</em> $\hat{\theta}$ bằng công thức $(\ref{bias})$.</p>

<p>$$
\begin{aligned}
\text{bias}(\hat\theta) &amp;= \mathbb{E}(\hat{\theta}) - \theta \\<br />
&amp;= \mathbb{E}(\frac{1}{n} \sum_{i=1}^{n} x^{(i)}) - \theta \\<br />
&amp;= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}(x^{(i)}) - \theta \text{ (Tính chất của } \mathbb{E})\\<br />
&amp;= \frac{1}{n} \sum_{i=1}^{n} \theta - \theta \text{ (Tính chất của phân phối Bernoulli } \mathbb{E}(x^{(i)})=\theta )\\<br />
&amp;= 0
\end{aligned}
$$
Quá đẹp, vậy estimator $\hat{\theta}$ không bị <em>bias</em>, con tim không cần suy nghĩ cũng đúng.</p>

<h4 id="ví-dụ-2">Ví dụ 2:</h4>

<p>Cho $G$ được mô tả bởi hàm phân phối xác suất Gaussian $\mathcal{N}(\mu, \sigma^2)$. Tập data sample $D={x^{(1)}, x^{(2)}, &hellip;, x^{(n)}}$ được chọn ra từ $G$.
Yêu câu giờ là đi tìm $\sigma^2$ từ $D$.</p>

<p>Cũng là con tim mách bảo: vì $\sigma^2$ là hệ số Variance của Gaussian, nên như ví dụ 1, mình cũng đi tìm Variance của $D$ là cho kết quả đúng thôi.
Gọi $\hat{\sigma}^2$ là <em>estimator</em> của chúng ta, tức là:
$$\hat{\sigma}^2 = \text{Var} (D)$$
Check lại <em>bias</em>:
\begin{align}
\text{bias}(\hat{\sigma}^2) &amp;= \mathbb{E}(\hat{\sigma}^2) - \sigma^2 \\<br />
&amp;= \mathbb{E}[\text{Var}(D)] - \sigma^2 \\<br />
\mathbb{E}[\text{Var}(D)] &amp;= \mathbb{E}\{\mathbb{E}[(x^{(i)} - \hat{\mu})^2]\}  \text{ (Định nghĩa của Var, với } \hat{\mu} = \frac{1}{n}\sum_{i=1}^{n}x^{(i)}) \\<br />
&amp;= \mathbb{E}[\frac{1}{n}\sum_{i=1}^{n}(x^{(i)} - \hat{\mu})^2]  \text{ (Định nghĩa của } \mathbb{E}) \\<br />
&amp;= \frac{1}{n}\mathbb{E}[\sum_{i=1}^{n}(x^{(i)} - \frac{1}{n}\sum_{j=1}^{n}x^{(j)})^2]  \\<br />
&amp;= \frac{1}{n}\mathbb{E}[\sum_{i=1}^{n}\frac{((n-1)x^{(i)} - \sum_{j=1, j\neq i}^{n}x^{(j)})^2}{n^2}]  \\<br />
&amp;= \frac{1}{n}\mathbb{E}[\sum_{i=1}^{n}\frac{(n-1)^2x^{(i)2} - 2 \times (n-1)x^{(i)} \times \sum_{j=1, j\neq i}^{n}x^{(j)} + (\sum_{j=1, j\neq i}^{n}x^{(j)})^2 }{n^2}]  \\<br />
&amp;= \frac{1}{n}\sum_{i=1}^{n}\frac{(n-1)^2\mathbb{E}[x^{2}] - 2 \times (n-1)\mathbb{E}[x^{(i)} \times \sum_{j=1, j\neq i}^{n}x^{(j)}] + \mathbb{E}[(\sum_{j=1, j\neq i}^{n}x^{(j)})^2] }{n^2}]  \\<br />
&amp;= \frac{1}{n^3}\sum_{i=1}^{n}[(n-1)^2\mathbb{E}[x^{2}] - 2 \times (n-1)\mathbb{E}[x^{(i)} \times \sum_{j=1, j\neq i}^{n}x^{(j)}] + \mathbb{E}[(\sum_{j=1, j\neq i}^{n}x^{(j)})^2]] \\<br />
&amp;= \frac{1}{n^3}\sum_{i=1}^{n}[(n-1)^2A - 2 \times (n-1)B + C]  \tag{2.1} \label{2.1} \\<br />
\end{align}
Căng dữ, tính từng cái $A, B, C$ cho đỡ nhức đầu:
\begin{align}
A &amp;= \mathbb{E}[x^{2}] \tag{2.2} \label{2.2} \\<br />
B &amp;= \mathbb{E}[x^{(i)} \times \sum_{j=1, j\neq i}^{n}x^{(j)}]\\<br />
&amp;= \mathbb{E}[x^{(i)}] \times \mathbb{E}[\sum_{j=1, j\neq i}^{n}x^{(j)}] \text{ (} x^{(i)} \text{độc lập với} \sum_{j=1, j\neq i}^{n}x^{(j)}) \\<br />
&amp;= \mathbb{E}[x] \times \sum_{j=1, j\neq i}^{n}\mathbb{E}[x] \\<br />
&amp;= \mathbb{E}[x] \times (n-1)\mathbb{E}[x] \\<br />
&amp;= (n-1)(\mathbb{E}[x])^2\\\ \tag{2.3} \label{2.3}
\end{align}
Để tính $C$, không mất tính tổng quá, chọn $i=1$
\begin{align}
C &amp;= \mathbb{E}[(\sum_{j=1, j\neq i}^{n}x^{(j)})^2] \\<br />
C &amp;= \mathbb{E}[(x^{(2)} + x^{(3)} + &hellip; + x^{(n)})^2] \\<br />
&amp;= \mathbb{E}[(x^{(2)} + x^{(3)} + &hellip; + x^{(n)}) \times (x^{(2)} + x^{(3)} + &hellip; + x^{(n)})] \\<br />
&amp;= \begin{aligned}[t]
\mathbb{E}[
&amp;x^{(2)2} + x^{(2)}x^{(3)} + &hellip; + x^{(2)}x^{(n)} + \\<br />
&amp;x^{(3)}x^{(2)} + x^{(3)2} + &hellip; + x^{(3)}x^{(n)} + \\<br />
&amp;x^{(4)}x^{(2)} + x^{(4)}x^{(3)} + &hellip; + x^{(4)}x^{(n)} + \\<br />
&amp;x^{(n)}x^{(2)} + x^{(n)}x^{(3)} + &hellip; + x^{(n)2}]
\end{aligned} \\<br />
&amp;= \begin{aligned}[t]
[
&amp;\mathbb{E}(x^{(2)2}) + \mathbb{E}(x^{(2)}x^{(3)}) + &hellip; + \mathbb{E}(x^{(2)}x^{(n)}) + \\<br />
&amp;\mathbb{E}(x^{(3)}x^{(2)}) + \mathbb{E}(x^{(3)2}) + &hellip; + \mathbb{E}(x^{(3)}x^{(n)}) + \\<br />
&amp;\mathbb{E}(x^{(4)}x^{(2)}) + \mathbb{E}(x^{(4)}x^{(3)}) + &hellip; + \mathbb{E}(x^{(4)}x^{(n)}) + \\<br />
&amp;\mathbb{E}(x^{(n)}x^{(2)}) + \mathbb{E}(x^{(n)}x^{(3)}) + &hellip; + \mathbb{E}(x^{(n)2})]
\end{aligned} \\<br />
&amp;=(n-1)\mathbb{E}[x^2] + (n-1)(n-2)(\mathbb{E}[x])^2 \tag{2.4} \label{2.4} \\<br />
\end{align}</p>

<p>Thay hết \ref{2.2}, \ref{2.3}, \ref{2.4} vào \ref{2.1}, ta có:
\begin{align}
\mathbb{E}[\text{Var}(D)] &amp;= \frac{1}{n^3}\sum_{i=1}^{n}[(n-1)^2A - 2 \times (n-1)B + C] \\<br />
&amp;= \frac{1}{n^3}\sum_{i=1}^{n}[(n-1)^2\mathbb{E}[x^{2}] - 2 \times (n-1)^2(\mathbb{E}[x])^2 + (n-1)\mathbb{E}[x^2] + (n-1)(n-2)(\mathbb{E}[x])^2] \\<br />
&amp;= \frac{1}{n^3}\sum_{i=1}^{n}[n(n-1)\mathbb{E}[x^{2}] - n(n-1)(\mathbb{E}[x])^2 ] \\<br />
&amp;= \frac{n-1}{n^2}\sum_{i=1}^{n}[\mathbb{E}[x^{2}] - (\mathbb{E}[x])^2 ] \\<br />
&amp;= \frac{n-1}{n^2}\sum_{i=1}^{n}\text{Var}(x) \text{ (Định nghĩa của Var, tham khảo [3])} \\<br />
&amp;= \frac{n-1}{n}\text{Var}(x) \\<br />
&amp;= \frac{n-1}{n}\sigma^2 \\<br />
\end{align}</p>

<p>Từ đó:
\begin{align}
\text{bias}(\hat{\sigma}^2) &amp;= \mathbb{E}(\hat{\sigma}^2) - \sigma^2 \\<br />
&amp;= \frac{n-1}{n}\sigma^2 - \sigma^2 \\<br />
&amp;= \frac{-1}{n}\sigma^2 \neq 0 \\<br />
\end{align}
Sau chặng đường dài, lần này lý trí thắng, <em>estimator</em> này bị <em>bias</em>.</p>

<h3 id="1-2-kết-lại">1.2 Kết lại</h3>

<p>Hai cái ví dụ, một mớ tính toán chỉ là phần kỹ thuật, cốt lõi là để thấy rằng những cảm nhận ban đầu tưởng như đúng (như $\mathbb{E}$ của $D$ thì may mắn đúng bằng $\mathbb{E}$ của $G$ luôn), nhưng nhiều trường hợp lại sai khác ($\text{Var}$ của $G$ với phân phối Gaussian không bằng $\text{Var}$ của $D$).</p>

<p>Về phần tính toán, ví dụ 1 thì đơn giản, tham khảo theo sách [1], ví dụ 2 căng hơn xíu, cái cách trên là mình tự làm (có phần bỏ sức trâu bò), có cách chứng minh tinh tế hơn, tham khảo số tại <a href="https://stats.stackexchange.com/questions/136673/how-to-understand-that-mle-of-variance-is-*bias*ed-in-a-gaussian-distribution/136703#136703?s=908df983477d41b1b3ed0e34a316166e">đây</a>. Ví dụ 2 này cũng được nhắc đến trong sách số [2], tác giả dùng để đưa đến khái niệm <em>bias</em>, nhưng chỉ <del>lước</del> lướt qua.</p>

<p>Toàn bộ nội dung chính của bài viết này lấy từ 5.4.2 sách [1] (trừ phần chứng minh của ví dụ 2, sách không thèm làm).</p>

<p>Câu hỏi đặt ra là:</p>

<ul>
<li>Việc một estimator bị <em>bias</em> thì ảnh hưởng như thế nào đến quá trình training ?</li>
<li>Như phần đầu có nói, trực giác thì thấy rằng <em>unbiased estimator</em> thì tốt hơn <em>biased estimator</em>, tuy nhiên có phải luôn luôn như vậy ? Có phải trong thực tế chọn <em>estimator</em> không <em>bias</em> luôn luôn là tốt nhất ?</li>
</ul>

<h2 id="2-variance">2. Variance</h2>

<p>Đuối &hellip;</p>

<h2 id="tham-khảo">Tham khảo</h2>

<p>[1] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning, vol. 13, no. 1. 2015.</p>

<p>[2] Bishop, Christopher M. &ldquo;Pattern recognition.&rdquo; Machine Learning 128 (2006): 1-58.</p>

<p>[3] Probability and Statistics
Cookbook: <a href="http://pages.cs.wisc.edu/~tdw/files/cookbook-en.pdf">http://pages.cs.wisc.edu/~tdw/files/cookbook-en.pdf</a></p>

</main>

    <footer>
      
<script async src="//yihui.name/js/center-img.js"></script>


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {
  	inlineMath: [['$','$'], ['\\(','\\)']],
  	displayMath: [['$$','$$'], ['\\[','\\]']],
  	processEscapes: true
  }});
</script>

      
      <hr/>
      Blog | <a href="https://github.com/ductri">Github</a> | <a href="https://www.facebook.com/ductrivn">Facebook</a>
      
    </footer>
  </body>
</html>

