@article{ziegler2019fine,
author = {Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey}, 
booktitle = {}, 
journal = {arXiv preprint arXiv:1909.08593}, 
pages = {}, 
volume = {}, 
title = {Fine-tuning language models from human preferences}, 
year = {2019}, 
}
@article{christiano2017deep,
author = {Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario}, 
booktitle = {}, 
journal = {Advances in neural information processing systems}, 
pages = {}, 
volume = {30}, 
title = {Deep reinforcement learning from human preferences}, 
year = {2017}, 
}
@article{rafailov2023direct,
author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea}, 
booktitle = {}, 
journal = {arXiv preprint arXiv:2305.18290}, 
pages = {}, 
volume = {}, 
title = {Direct preference optimization: Your language model is secretly a reward model}, 
year = {2023}, 
}
@article{xu2023some,
author = {Xu, Jing and Lee, Andrew and Sukhbaatar, Sainbayar and Weston, Jason}, 
booktitle = {}, 
journal = {arXiv preprint arXiv:2312.16682}, 
pages = {}, 
volume = {}, 
title = {Some things are more cringe than others: Preference optimization with the pairwise cringe loss}, 
year = {2023}, 
}
