---
layout: post
title: Leetcode Pratice
date: 2024-02-09 21:23:00
description: Enough of quantization jargons
tags: matric completion, nmf, 
categories: note
published: false
usemathjax: false
pdf_dir: 
---

A summary of my strategy on solving programming problems on leetcode and the similar.
<!--more-->
from our repo:
- alignment without finetuning
- distributional finetuning


* Chain-of-thought papers
The original chain-of-thought, from Google Research: chain-of-thought prompting elicits reasoning in LLMs.

- Promoting model generating intermediate steps before arriving at the final answers. 
- Although the idea looks natural, ideal for human reason, how to make sure the reasoning steps are "sound".
- What are the training data?
+ (input, chain of thought, output)
- What is the loss function?
+ does not require training at all

- two ideas: arithmetic reasoning, in-context few-shot learning via prompting.

So this paper is straightforward, extremely simple idea. But it worked magically well.
So that makes us rethinking about the capability of LLMs and what can we do with it.
Key pros: NO TRAINING at all
Key question: how to enable it specifically?


* Tree-of-thought: another publication from google, this time deepmind.

Side note: a different view about problem-solving using llm.
This is even crazier! It needs to generate unit of thought, but how?

These type of method can be categorized as prompt engineering.

* The chain of preference optimization: bad

Okay, this paper is worth reading: Getting More Juice Out of the SFT Data: Reward Learning from Human Demonstration Improves SFT for LLM Alignment

Not a good paper, but might be suggest a good problem:
- Aligning LLM Agents by Learning Latent Preference from User Edits
- HYDRA: Model Factorization Framework for Black-Box LLM Personalization
- Aligner: Efficient Alignment by Learning to Correct

Definitely note a good paper, but maybe a good empirical evidence of something could work:
- LoFiT: Localized Fine-tuning on LLM Representations


Other topics: memory/computation efficiency (subtopic: quantization)


