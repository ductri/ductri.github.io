\documentclass[11pt,a4paper]{article}
\usepackage{tri_preamble}

% --------------------------------------------------------- 
% TITLE, AUTHORS, ...
% --------------------------------------------------------- 
\title{Title}
\author{	Tri Nguyen \\\\
        \texttt{nguyetr9@oregonstate.edu} \\\\
        }
% --------------------------------------------------------- 
% BEGIN DOCUMENT
% --------------------------------------------------------- 
\begin{document}
\maketitle

Given an unknown matrix $\bm{X} \in \mathbb{R}^{N \times N}$. We would like to learn this matrix given some signals about some of its elements. In particular, for some randomly chosen position $(i,j)$, we obtain
\[
y_{ij} \sim \text{some probability pdf with parameter } x_{ij}
\] 

There are 2 sources of difficulties:
\begin{itemize}
\item The set of indices $\Omega \subset [N] \times [N]$ usually does not cover the whole $[N] \times [N]$, leaving some positions in $\bm{X}$ never been implicitly observed.
\item Even at the selected position $(i,j)$, the observation $y_{i,j}$ is not exactly $x_{i,j}$ but only a random variable affected by $x_{i,j}$. This loss of information adds another layer of difficulty in recovering $\bm{X}$.
\end{itemize}
Luckily, the latter issue can be somewhat circumvented by acquiring more and more samples. The number of samples required for a certain accuracy depends on the pdf as well as the role of parameter $x_{ij}$ to that pdf. Our interest is however, on the former issue.

For that, lets assume a pretty simple case:
\[
\pr{y_{ij}=1} = x_{ij}.
\] 
This means that we use the Bernoulli distribution as the pdf, and $x_{ij}$ is the mean of the distribution. Consider a simple unbiased mean estimator, i.e., 
\[
\widehat{x}_{ij} = \dfrac{1}{\abs{\Omega_{ij}}}\sum^{\abs{\Omega_{ij}}}_{i=1} x_{\omega},
\] 
then we know the sample complexity is
\[
    \mathop{\mathbb{E}}[(\widehat{x}_{ij} - x_{ij})^2] \leq 
\] 

Now, lets unify the task. We wish to establish the following relation: Given an estimator $\widehat{\bm{X}}$ of $\bm{X}$ given observed dataset $\bm{S}$, the following holds with probability at least $1-\delta$:
\[
d(\widehat{\bm{X}}, \bm{X}) \leq g(S, \delta),
\] 
where $d$ is some metric function, usually $\norm{\cdot}_{\rm F}^2$ in this case, $g(S, \delta)$ is a non-decreasing function of number of samples and the probability $\delta \in [0,1]$. In our goal specifically is to define $d$ (easy part) and find the concrete function $g(S, \delta)$ so that the above statement holds true.

\paragraph{Why?} Through several examples, we will see how the underlying structure of $\bm{X}$ affect sample complexity $g(S, \delta)$. In particular, we will go through following cases:
\begin{itemize}
    \item No structure at all :)))
    \item Low rank structure, $\bm{X} = \bm{W} \bm{H}^{\T}$, where $\bm{W}, \bm{H} \in \mathbb{R}^{N \times K}, K \ll N$
    \item Neural network model: $x_{ij} = f(\bm{z}_{ij})$, where $\bm{z}_{ij} \in \mathbb{R}^{d}$ is certain obtained feature for position $(i,j)$, and $f: \mathcal{D} \to [0,1]$.
\end{itemize}
Each of these structures should be carefully selected and justified depending on application.


\end{document}

